{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check wheter expected interaction reward matches with environment reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SINGLE ITERATION/SESSION REWARDS FOR CONFIG [3 2 0 1 0]:\n",
      "   - [EMPIRICAL] Mean reward (500 experiments from env): 22.06977460450791\n",
      "   - [THEORETICAL] Graph expected reward: 38.8\n",
      "   - [THEORETICAL] Baseline expected reward: 19.290399999999998\n",
      "   - [THEORETICAL] One-Step expected reward: 32.800000000000004\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from Environment import Environment\n",
    "from Model.Evaluator.GraphEvaluator import GraphEvaluator\n",
    "from Model.Evaluator.Baseline import Baseline\n",
    "from Model.Evaluator.OneStepEvaluator import OneStepEvaluator\n",
    "\n",
    "from Model.Product import *\n",
    "import numpy as np\n",
    "\n",
    "# ==== PARAMETERS TO CHANGE ====\n",
    "config_path = \"./Configs/config3.json\"\n",
    "RANDOM_ARM = True\n",
    "arm = [1, 2, 0, 1, 0]\n",
    "n_experiments = 500\n",
    "# ==============================\n",
    "\n",
    "f = open(config_path)\n",
    "config = json.load(f)\n",
    "f.close()\n",
    "\n",
    "env = Environment(config_path=config_path)\n",
    "marginsPerPrice = config[\"margins\"]\n",
    "\n",
    "if RANDOM_ARM:\n",
    "    arm = np.floor(np.random.rand(len(marginsPerPrice)) * len(marginsPerPrice[0]))\n",
    "    arm = np.array(arm.tolist(), dtype=int)\n",
    "\n",
    "margins = [marginsPerPrice[i][arm[i]] for i in range(0,len(arm))]\n",
    "# print(margins)\n",
    "obtained_margins = []\n",
    "\n",
    "conf_classes = config[\"classes\"]\n",
    "for uc in conf_classes:\n",
    "    armConvRates = [uc[\"conversionRates\"][i][arm[i]] for i in range(0,len(arm))]\n",
    "    productList = [Product(int(key), uc[\"secondary\"][key]) for key in uc[\"secondary\"]]\n",
    "    eval = GraphEvaluator(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                alphas=uc[\"alphas\"], margins=margins, units_mean=uc[\"unitsShape\"], convert_units=True, verbose=False)\n",
    "    baseline = Baseline(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                alphas=uc[\"alphas\"], margins=margins, units_mean=uc[\"unitsShape\"], convert_units=True, verbose=False)\n",
    "    oneStep = OneStepEvaluator(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                alphas=uc[\"alphas\"], margins=margins, units_mean=uc[\"unitsShape\"], verbose=False)\n",
    "\n",
    "env.setPriceLevels(arm)\n",
    "for i in range(0,n_experiments):\n",
    "  inters = env.round()\n",
    "  total = 0\n",
    "  for inter in inters:\n",
    "    total += inter.linearizeMargin(marginsPerPrice)\n",
    "    obtained_margins.append(inter.linearizeMargin(marginsPerPrice))\n",
    "  total = total / len(inters)\n",
    "  # obtained_margins.append(total)\n",
    "\n",
    "print(\"SINGLE ITERATION/SESSION REWARDS FOR CONFIG {}:\".format(arm))\n",
    "print(\"   - [EMPIRICAL] Mean reward ({} experiments from env): {}\".format(n_experiments, np.array(obtained_margins).mean()))\n",
    "print(\"   - [THEORETICAL] Graph expected reward: {}\".format(eval.computeMargin()))\n",
    "print(\"   - [THEORETICAL] Baseline expected reward: {}\".format(baseline.computeMargin()))\n",
    "print(\"   - [THEORETICAL] One-Step expected reward: {}\".format(oneStep.computeMargin()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the best arm for each class by brute force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRUTE FORCE OF CONFIG ./Configs/configuration4.json CLASSES:\n",
      "   - [CLASS 0] Optimal arm is [3, 3, 3, 3, 3] with margin 34.5\n",
      "   - [CLASS 1] Optimal arm is [0, 3, 0, 3, 3] with margin 25.150000000000002\n",
      "   - [CLASS 2] Optimal arm is [3, 3, 3, 3, 3] with margin 32.800000000000004\n",
      "\n",
      "The optimal weighted mean expected margin given the mean daily users [30 30 20] is 30.56875\n",
      "\n",
      "Which arm among the best ones gives the better results in non contextual optmization?\n",
      "   - [ARM [3, 3, 3, 3, 3]] Class-weighted expected margin is 32.35625\n",
      "   - [ARM [0, 3, 0, 3, 3]] Class-weighted expected margin is 30.50625\n",
      "   - [ARM [3, 3, 3, 3, 3]] Class-weighted expected margin is 32.35625\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from Environment import Environment\n",
    "import numpy as np\n",
    "from Learner.BruteForce import *\n",
    "from Model.UserClass import *\n",
    "from Model.Product import *\n",
    "from Model.GraphProbabilities import *\n",
    "from Model.Evaluator.GraphEvaluator import GraphEvaluator\n",
    "from Model.Evaluator.Baseline import Baseline\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "\n",
    "# ==== PARAMETERS TO CHANGE ====\n",
    "CONFIG_PATH = './Configs/configuration4.json'\n",
    "# ==============================\n",
    "\n",
    "\n",
    "f = open(CONFIG_PATH)\n",
    "config = json.load(f)\n",
    "f.close()\n",
    "\n",
    "opt_arms = []\n",
    "opt_margins = []\n",
    "daily_users = []\n",
    "print(\"Starting the analysis ...\\n\")\n",
    "for k in range(0, len(config[\"classes\"])):\n",
    "    uc = config[\"classes\"][k]\n",
    "\n",
    "    productList = [Product(int(key), uc[\"secondary\"][key]) for key in uc[\"secondary\"]]\n",
    "\n",
    "    conversionRateLevels = uc[\"conversionRates\"]\n",
    "    marginsPerPrice = config[\"margins\"]\n",
    "    click_prob = np.array(uc[\"clickProbability\"])\n",
    "    lambda_p = uc[\"lambda\"]\n",
    "    alphas = uc[\"alphas\"]\n",
    "    units_mean = uc[\"actualUnitsMean\"]\n",
    "    # Early transform for efficiency reason\n",
    "    # actual_means = []\n",
    "    # for i in range(0,len(units_mean)):\n",
    "    #    empiric_mean = np.ceil(np.random.gamma(units_mean[i], 1, size=1000000)).mean()\n",
    "    #     actual_means.append(int(empiric_mean*100) / 100)\n",
    "    # units_mean = actual_means\n",
    "\n",
    "    daily_users.append(uc[\"usersMean\"])\n",
    "    num_prices = len(conversionRateLevels[0])\n",
    "    num_prods = len(alphas)\n",
    "\n",
    "    print(\"Brute forcing class {}\".format(k))\n",
    "    bf = BruteForce(num_prices=num_prices, num_products=num_prods)\n",
    "    for i in tqdm(range(0, num_prices**num_prods)):\n",
    "        pulledArm = bf.pull_arm()\n",
    "        margins = []\n",
    "        convRates = []\n",
    "        for k in range(0,len(pulledArm)):\n",
    "            margins.append(marginsPerPrice[k][pulledArm[k]])\n",
    "            convRates.append(conversionRateLevels[k][pulledArm[k]])\n",
    "\n",
    "        price_configuration_margin = 0\n",
    "        eval = GraphEvaluator(products_list=productList, click_prob_matrix=click_prob, lambda_prob=lambda_p, conversion_rates=convRates,\n",
    "                        alphas=alphas, margins=margins, units_mean=units_mean, convert_units=False, verbose=False)\n",
    "        eval2 = Baseline(products_list=productList, click_prob_matrix=click_prob, lambda_prob=lambda_p, conversion_rates=convRates,\n",
    "                        alphas=alphas, margins=margins, units_mean=units_mean, convert_units=False, verbose=False)\n",
    "\n",
    "        overall_margin = eval.computeMargin()\n",
    "        baseline = eval2.computeMargin()\n",
    "        # print(\"Configuration {}; ConvRates {}; Margins {}; Overall Margin {}; Baseline {}\".format(pulledArm,convRates,margins,int(overall_margin*100)/100,int(baseline*100)/100))\n",
    "        # if overall_margin < baseline:\n",
    "            # print(\"VAFFANCULOOOOO {} - {} = {}\".format(overall_margin,baseline,overall_margin-baseline))\n",
    "        bf.update(overall_margin)\n",
    "\n",
    "    opt_arms.append(bf.get_optima())\n",
    "    opt_margins.append(bf.get_optima_margin())\n",
    "clear_output(wait=True)\n",
    "print(\"BRUTE FORCE OF CONFIG {} CLASSES:\".format(CONFIG_PATH))\n",
    "for i in range(0,len(opt_arms)):\n",
    "    print(\"   - [CLASS {}] Optimal arm is {} with margin {}\".format(i,opt_arms[i], opt_margins[i]))\n",
    "\n",
    "daily_users = np.array(daily_users)\n",
    "classes_weights = daily_users / daily_users.sum()\n",
    "opt_margins = np.array(opt_margins)\n",
    "print(\"\\nThe optimal weighted mean expected margin given the mean daily users {} is {}\".format(daily_users, np.multiply(classes_weights, opt_margins).sum()))\n",
    "\n",
    "# Best single arm possible\n",
    "print(\"\\nWhich arm among the best ones gives the better results in non contextual optmization?\")\n",
    "equal_arm_rew = []\n",
    "for i in range(0,len(opt_arms)):\n",
    "    arm = opt_arms[i]\n",
    "    class_rewards = []\n",
    "    for k in range(0, len(config[\"classes\"])):\n",
    "        uc = config[\"classes\"][k]\n",
    "        productList = [Product(int(key), uc[\"secondary\"][key]) for key in uc[\"secondary\"]]\n",
    "        conversionRateLevels = uc[\"conversionRates\"]\n",
    "        marginsPerPrice = config[\"margins\"]\n",
    "        click_prob = np.array(uc[\"clickProbability\"])\n",
    "        lambda_p = uc[\"lambda\"]\n",
    "        alphas = uc[\"alphas\"]\n",
    "        units_mean = uc[\"unitsShape\"]\n",
    "        num_prices = len(conversionRateLevels[0])\n",
    "        num_prods = len(alphas)\n",
    "\n",
    "        pulledArm = arm\n",
    "        margins = []\n",
    "        convRates = []\n",
    "        for k in range(0,len(pulledArm)):\n",
    "            margins.append(marginsPerPrice[k][pulledArm[k]])\n",
    "            convRates.append(conversionRateLevels[k][pulledArm[k]])\n",
    "\n",
    "        eval = GraphEvaluator(products_list=productList, click_prob_matrix=click_prob, lambda_prob=lambda_p, conversion_rates=convRates,\n",
    "                        alphas=alphas, margins=margins, units_mean=units_mean, verbose=False)\n",
    "        eval2 = Baseline(products_list=productList, click_prob_matrix=click_prob, lambda_prob=lambda_p, conversion_rates=convRates,\n",
    "                        alphas=alphas, margins=margins, units_mean=units_mean, verbose=False)\n",
    "                    \n",
    "        class_rewards.append(eval.computeMargin())\n",
    "    \n",
    "    weighted_reward = np.multiply(classes_weights, np.array(class_rewards)).sum()\n",
    "    equal_arm_rew.append(weighted_reward)\n",
    "    if class_rewards[i] < eval2.computeMargin():\n",
    "        print(\"   - [ARM {}] Class-weighted expected margin is {}, but baseline is greater than weighted\".format(arm, weighted_reward))\n",
    "    else:\n",
    "        print(\"   - [ARM {}] Class-weighted expected margin is {}\".format(arm, weighted_reward))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average distance from Environment data and GraphEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERCENTAGE ERROR OF GRAPH EVALUATOR FROM ENVIRONMENT (./Configs/config3.json):\n",
      "   - [MEAN] 0.5032961892238179\n",
      "   - [STD] 0.23131999345319565\n",
      "   - [MAX] 1.363867790668559\n",
      "   - [MIN] 0.03304399780923764\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from Environment import Environment\n",
    "from Model.Evaluator.GraphEvaluator import GraphEvaluator\n",
    "from Model.Evaluator.Baseline import Baseline\n",
    "from Model.Evaluator.OneStepEvaluator import OneStepEvaluator\n",
    "from Learner.BruteForce import *\n",
    "from Model.Product import *\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# ==== PARAMETERS TO CHANGE ====\n",
    "config_path = \"./Configs/config3.json\"\n",
    "RANDOM_ARM = False\n",
    "n_experiments = 100\n",
    "# ==============================\n",
    "\n",
    "f = open(config_path)\n",
    "config = json.load(f)\n",
    "f.close()\n",
    "\n",
    "env = Environment(config_path=config_path)\n",
    "marginsPerPrice = config[\"margins\"]\n",
    "num_prods = len(config[\"margins\"])\n",
    "num_prices = len(config[\"margins\"][0])\n",
    "\n",
    "evaluatorEnvDifference = []\n",
    "\n",
    "bf = BruteForce(num_prices=num_prices, num_products=num_prods)\n",
    "for i in tqdm(range(0, num_prices**num_prods)):\n",
    "  arm = bf.pull_arm() \n",
    "  margins = [marginsPerPrice[i][arm[i]] for i in range(0,len(arm))]\n",
    "  # print(margins)\n",
    "  obtained_margins = []\n",
    "\n",
    "  conf_classes = config[\"classes\"]\n",
    "  for uc in conf_classes:\n",
    "      armConvRates = [uc[\"conversionRates\"][i][arm[i]] for i in range(0,len(arm))]\n",
    "      productList = [Product(int(key), uc[\"secondary\"][key]) for key in uc[\"secondary\"]]\n",
    "      eval = GraphEvaluator(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                  alphas=uc[\"alphas\"], margins=margins, units_mean=uc[\"actualUnitsMean\"], convert_units=False, verbose=False)\n",
    "      baseline = Baseline(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                  alphas=uc[\"alphas\"], margins=margins, units_mean=uc[\"actualUnitsMean\"], convert_units=False, verbose=False)\n",
    "      oneStep = OneStepEvaluator(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                  alphas=uc[\"alphas\"], margins=margins, units_mean=uc[\"actualUnitsMean\"], verbose=False)\n",
    "\n",
    "  env.setPriceLevels(arm)\n",
    "  for i in range(0,n_experiments):\n",
    "    inters = env.round()\n",
    "    total = 0\n",
    "    for inter in inters:\n",
    "      total += inter.linearizeMargin(marginsPerPrice)\n",
    "      obtained_margins.append(inter.linearizeMargin(marginsPerPrice))\n",
    "    total = total / len(inters)\n",
    "    # obtained_margins.append(total)\n",
    "  \n",
    "  environmentMean = np.array(obtained_margins).mean()\n",
    "  # Percentage error of graph eval from environment\n",
    "  evaluatorEnvDifference.append(abs(environmentMean - eval.computeMargin()) / environmentMean)\n",
    "\n",
    "clear_output(wait=True)\n",
    "evaluatorEnvDifference = np.array(evaluatorEnvDifference)\n",
    "print(\"PERCENTAGE ERROR OF GRAPH EVALUATOR FROM ENVIRONMENT ({}):\".format(config_path))\n",
    "print(\"   - [MEAN] {}\".format(evaluatorEnvDifference.mean()))\n",
    "print(\"   - [STD] {}\".format(evaluatorEnvDifference.std()))\n",
    "print(\"   - [MAX] {}\".format(evaluatorEnvDifference.max()))\n",
    "print(\"   - [MIN] {}\".format(evaluatorEnvDifference.min()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Evaluator vs Environment visiting probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIFFERENCE FROM ENVIRONMENT AND GE VISITING PROBABILITY, ARM [0 1 1 0 2] (./Configs/config3.json):\n",
      "   - [ENV] [0.34301645 0.40334541 0.41683858 0.3604126  0.37914692]\n",
      "      - [STARTING 0] [0.99994403 0.3489869  0.36986455 0.18319713 0.17625658]\n",
      "      - [STARTING 1] [0.03267791 1.         0.24220757 0.12842141 0.18489554]\n",
      "      - [STARTING 2] [0.13689744 0.10888044 1.         0.51219103 0.4247847 ]\n",
      "      - [STARTING 3] [0.2581871  0.12982005 0.1066838  1.         0.29523863]\n",
      "      - [STARTING 4] [0.01475042 0.17134044 0.04273696 0.06029164 1.        ]\n",
      "\n",
      "   - [G/E CLASS 0] [0.52158577 0.64772205 0.38838941 0.19775595 0.24047966]\n",
      "      - [STARTING 0] [1.         0.46615872 0.493344   0.21619248 0.23390821]\n",
      "      - [STARTING 1] [0.02490137 1.         0.2403631  0.10350908 0.17698683]\n",
      "      - [STARTING 2] [0.09891594 0.10980953 1.         0.408064   0.35468739]\n",
      "      - [STARTING 3] [0.24       0.15742597 0.13659287 1.         0.28477755]\n",
      "      - [STARTING 4] [0.01561942 0.18425088 0.04914614 0.06445056 1.        ]\n",
      "   - [G/E CLASS 1] [0.17135884 0.17809677 0.45185119 0.50903098 0.5264769 ]\n",
      "      - [STARTING 0] [1.         0.2146563  0.230784   0.13633735 0.14165051]\n",
      "      - [STARTING 1] [0.03440956 1.         0.24016138 0.1428961  0.2085651 ]\n",
      "      - [STARTING 2] [0.13830891 0.11976096 1.         0.56827904 0.47846928]\n",
      "      - [STARTING 3] [0.24       0.09594902 0.06737149 1.         0.27031361]\n",
      "      - [STARTING 4] [0.01725919 0.18188928 0.04584419 0.07103078 1.        ]\n",
      "   - [G/E CLASS 2] [0.34787599 0.39088939 0.4057502  0.45591661 0.55860209]\n",
      "      - [STARTING 0] [1.         0.46588759 0.503568   0.35953356 0.40904346]\n",
      "      - [STARTING 1] [0.07528303 1.         0.28032105 0.19566909 0.28896898]\n",
      "      - [STARTING 2] [0.26436133 0.18036263 1.         0.68365568 0.62354834]\n",
      "      - [STARTING 3] [0.384      0.21442278 0.21465352 1.         0.47144966]\n",
      "      - [STARTING 4] [0.01573558 0.09377395 0.03020843 0.04072474 1.        ]\n",
      "\n",
      "   - [G/E TOTAL] [0.34667283 0.40976369 0.41806743 0.36803963 0.40849597]\n",
      "\n",
      "PERFORMANCE INDEX => [0.00365638 0.00641828 0.00122884 0.00762703 0.02934905] => 0.009655916180039147\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from Environment import Environment\n",
    "from Model.Evaluator.GraphEvaluator import GraphEvaluator\n",
    "from Model.Evaluator.Baseline import Baseline\n",
    "from Model.Evaluator.OneStepEvaluator import OneStepEvaluator\n",
    "from Learner.BruteForce import *\n",
    "from Model.Product import *\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# ==== PARAMETERS TO CHANGE ====\n",
    "config_path = \"./Configs/config3.json\"\n",
    "RANDOM_ARM = True\n",
    "arm = [0, 0, 0, 0, 0]\n",
    "n_experiments = 250\n",
    "# ==============================\n",
    "\n",
    "f = open(config_path)\n",
    "config = json.load(f)\n",
    "f.close()\n",
    "\n",
    "env = Environment(config_path=config_path)\n",
    "marginsPerPrice = config[\"margins\"]\n",
    "num_prods = len(config[\"margins\"])\n",
    "num_prices = len(config[\"margins\"][0])\n",
    "\n",
    "if RANDOM_ARM:\n",
    "    arm = np.floor(np.random.rand(len(marginsPerPrice)) * len(marginsPerPrice[0]))\n",
    "    arm = np.array(arm.tolist(), dtype=int)\n",
    "env.setPriceLevels(arm)\n",
    "\n",
    "cumulative_visits = np.zeros(num_prods)\n",
    "cumulative_interactions = 0\n",
    "for i in tqdm(range(0,n_experiments)):\n",
    "    interactions = env.round()\n",
    "    cumulative_interactions += len(interactions)\n",
    "    for inter in interactions:\n",
    "        cumulative_visits = cumulative_visits + inter.linearizeVisits()\n",
    "clear_output(wait=True)\n",
    "\n",
    "environment_probs = cumulative_visits / cumulative_interactions\n",
    "print(\"DIFFERENCE FROM ENVIRONMENT AND GE VISITING PROBABILITY, ARM {} ({}):\".format(arm, config_path))\n",
    "print(\"   - [ENV] {}\".format(environment_probs))\n",
    "\n",
    "\n",
    "for j in range(0,num_prods):\n",
    "    for k in range(0,len(config[\"classes\"])):\n",
    "        env.classes[k].alphas = np.full(num_prods, 0.000001).tolist()\n",
    "        env.classes[k].alphas[j] = 1.00004\n",
    "    cumulative_visits = np.zeros(num_prods)\n",
    "    cumulative_interactions = 0\n",
    "    for i in range(0,n_experiments):\n",
    "        interactions = env.round()\n",
    "        cumulative_interactions += len(interactions)\n",
    "        for inter in interactions:\n",
    "            cumulative_visits = cumulative_visits + inter.linearizeVisits()\n",
    "    print(\"      - [STARTING {}] {}\".format(j, cumulative_visits / cumulative_interactions))\n",
    "print(\"\")\n",
    "conf_classes = config[\"classes\"]\n",
    "i = 0\n",
    "weighted_classes = np.zeros((num_prods))\n",
    "tot_users_daily = 0\n",
    "for uc in conf_classes:\n",
    "    armConvRates = [uc[\"conversionRates\"][i][arm[i]] for i in range(0,len(arm))]\n",
    "    productList = [Product(int(key), uc[\"secondary\"][key]) for key in uc[\"secondary\"]]\n",
    "    eval = GraphEvaluator(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                alphas=uc[\"alphas\"], margins=marginsPerPrice, units_mean=uc[\"actualUnitsMean\"], convert_units=False, verbose=False)\n",
    "    visit_prob = eval.getVisitingProbability()\n",
    "    weighted_classes = weighted_classes + visit_prob * uc[\"usersMean\"]\n",
    "    tot_users_daily += uc[\"usersMean\"]\n",
    "    print(\"   - [G/E CLASS {}] {}\".format(i, visit_prob))\n",
    "    for k in range(0,num_prods):\n",
    "        print(\"      - [STARTING {}] {}\".format(k, eval.computeSingleProduct(k)))\n",
    "    i += 1\n",
    "\n",
    "print(\"\")\n",
    "ge_weighted_probs = weighted_classes / tot_users_daily\n",
    "print(\"   - [G/E TOTAL] {}\\n\".format(ge_weighted_probs))\n",
    "\n",
    "print(\"PERFORMANCE INDEX => {} => {}\".format(np.abs(ge_weighted_probs - environment_probs), np.abs(ge_weighted_probs - environment_probs).mean()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "14160fb0de3f36180f5e1dd791af52bebcb3f3583a6e540ccb943ed2b61e8d42"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
