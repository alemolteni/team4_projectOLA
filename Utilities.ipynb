{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check wheter expected interaction reward matches with environment reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SINGLE ITERATION/SESSION REWARDS FOR CONFIG [0 1 2 3 1]:\n",
      "   - [EMPIRICAL] Mean reward (500 experiments from env): 8.250265764001567\n",
      "\n",
      "   - [THEORY CLASS 0] Graph expected reward: 7.1512899999999995\n",
      "   - [THEORY CLASS 0] Baseline expected reward: 7.1512899999999995\n",
      "   - [THEORY CLASS 0] One-Step expected reward: 6.43\n",
      "\n",
      "   - [THEORY CLASS 1] Graph expected reward: 8.094100000000001\n",
      "   - [THEORY CLASS 1] Baseline expected reward: 8.094100000000001\n",
      "   - [THEORY CLASS 1] One-Step expected reward: 7.4\n",
      "\n",
      "   - [THEORY CLASS 2] Graph expected reward: 11.696\n",
      "   - [THEORY CLASS 2] Baseline expected reward: 11.696\n",
      "   - [THEORY CLASS 2] One-Step expected reward: 11.0\n",
      "\n",
      "   - [THEORETICAL] Graph expected reward weighted by [30 30 10]: 8.204595714285716\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from Environment import Environment\n",
    "from Model.Evaluator.GraphEvaluator import GraphEvaluator\n",
    "from Model.Evaluator.Baseline import Baseline\n",
    "from Model.Evaluator.OneStepEvaluator import OneStepEvaluator\n",
    "\n",
    "from Model.Product import *\n",
    "import numpy as np\n",
    "\n",
    "# ==== PARAMETERS TO CHANGE ====\n",
    "config_path = \"./Configs/config2.json\"\n",
    "RANDOM_ARM = True\n",
    "arm = [1, 1, 1, 1, 1]\n",
    "n_experiments = 500\n",
    "# ==============================\n",
    "\n",
    "f = open(config_path)\n",
    "config = json.load(f)\n",
    "f.close()\n",
    "\n",
    "env = Environment(config_path=config_path)\n",
    "marginsPerPrice = config[\"margins\"]\n",
    "\n",
    "if RANDOM_ARM:\n",
    "    arm = np.floor(np.random.rand(len(marginsPerPrice)) * len(marginsPerPrice[0]))\n",
    "    arm = np.array(arm.tolist(), dtype=int)\n",
    "\n",
    "margins = [marginsPerPrice[i][arm[i]] for i in range(0,len(arm))]\n",
    "# print(margins)\n",
    "obtained_margins = []\n",
    "\n",
    "conf_classes = config[\"classes\"]\n",
    "user_means = []\n",
    "evaluators = []\n",
    "for uc in conf_classes:\n",
    "    armConvRates = [uc[\"conversionRates\"][i][arm[i]] for i in range(0,len(arm))]\n",
    "    productList = [Product(int(key), uc[\"secondary\"][key]) for key in uc[\"secondary\"]]\n",
    "    eval = GraphEvaluator(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                alphas=uc[\"alphas\"], margins=margins, units_mean=uc[\"unitsShape\"], convert_units=True, verbose=False)\n",
    "    baseline = Baseline(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                alphas=uc[\"alphas\"], margins=margins, units_mean=uc[\"unitsShape\"], convert_units=True, verbose=False)\n",
    "    oneStep = OneStepEvaluator(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                alphas=uc[\"alphas\"], margins=margins, units_mean=uc[\"unitsShape\"], verbose=False)\n",
    "    evaluators.append((eval,baseline,oneStep))\n",
    "    user_means.append(uc[\"usersMean\"])\n",
    "user_means = np.array(user_means)\n",
    "\n",
    "env.setPriceLevels(arm)\n",
    "for i in range(0,n_experiments):\n",
    "  inters = env.round()\n",
    "  total = 0\n",
    "  for inter in inters:\n",
    "    total += inter.linearizeMargin(marginsPerPrice)\n",
    "    obtained_margins.append(inter.linearizeMargin(marginsPerPrice))\n",
    "  total = total / len(inters)\n",
    "  # obtained_margins.append(total)\n",
    "\n",
    "print(\"SINGLE ITERATION/SESSION REWARDS FOR CONFIG {}:\".format(arm))\n",
    "print(\"   - [EMPIRICAL] Mean reward ({} experiments from env): {}\\n\".format(n_experiments, np.array(obtained_margins).mean()))\n",
    "\n",
    "i = 0\n",
    "ge_margins = []\n",
    "for ev_group in evaluators:\n",
    "  ge_result = ev_group[0].computeMargin()\n",
    "  ge_margins.append(ge_result)\n",
    "  print(\"   - [THEORY CLASS {}] Graph expected reward: {}\".format(i, ge_result))\n",
    "  print(\"   - [THEORY CLASS {}] Baseline expected reward: {}\".format(i, ev_group[1].computeMargin()))\n",
    "  print(\"   - [THEORY CLASS {}] One-Step expected reward: {}\\n\".format(i, ev_group[2].computeMargin()))\n",
    "  i += 1\n",
    "\n",
    "print(\"   - [THEORETICAL] Graph expected reward weighted by {}: {}\".format(user_means, np.multiply(user_means, ge_margins).sum() / user_means.sum() ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class for config evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SINGLE ITERATION/SESSION REWARDS FOR CONFIG [3 0 0 3 3]:\n",
      "   - [EMPIRICAL] Mean reward (500 experiments from env): 9.200748791595652\n",
      "\n",
      "   - [THEORETICAL] Graph expected reward weighted by MultiClassEvaluator: 9.274597218033097\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from Environment import Environment\n",
    "from Model.Evaluator.MultiClassEvaluator import MultiClassEvaluator\n",
    "from Model.Product import *\n",
    "import numpy as np\n",
    "\n",
    "# ==== PARAMETERS TO CHANGE ====\n",
    "config_path = \"./Configs/config3.json\"\n",
    "RANDOM_ARM = True\n",
    "arm = [1, 1, 1, 1, 1]\n",
    "n_experiments = 500\n",
    "# ==============================\n",
    "\n",
    "NUM_PRODS = len(arm)\n",
    "mce = MultiClassEvaluator(config_path=config_path)\n",
    "\n",
    "f = open(config_path)\n",
    "config = json.load(f)\n",
    "f.close()\n",
    "\n",
    "env = Environment(config_path=config_path)\n",
    "marginsPerPrice = config[\"margins\"]\n",
    "NUM_PRODS = len(marginsPerPrice)\n",
    "NUM_PRICES = len(marginsPerPrice[0])\n",
    "\n",
    "\n",
    "if RANDOM_ARM:\n",
    "    arm = np.floor(np.random.rand(NUM_PRODS) * NUM_PRICES)\n",
    "    arm = np.array(arm.tolist(), dtype=int)\n",
    "\n",
    "env.setPriceLevels(arm)\n",
    "obtained_margins = []\n",
    "for i in range(0,n_experiments):\n",
    "  inters = env.round()\n",
    "  total = 0\n",
    "  for inter in inters:\n",
    "    total += inter.linearizeMargin(marginsPerPrice)\n",
    "    obtained_margins.append(inter.linearizeMargin(marginsPerPrice))\n",
    "  total = total / len(inters)\n",
    "  # obtained_margins.append(total)\n",
    "\n",
    "print(\"SINGLE ITERATION/SESSION REWARDS FOR CONFIG {}:\".format(arm))\n",
    "print(\"   - [EMPIRICAL] Mean reward ({} experiments from env): {}\\n\".format(n_experiments, np.array(obtained_margins).mean()))\n",
    "print(\"   - [THEORETICAL] Graph expected reward weighted by MultiClassEvaluator: {}\".format(mce.computeMargin(arm)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average distance from Environment data and GraphEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERCENTAGE ERROR OF GRAPH EVALUATOR FROM ENVIRONMENT (./Configs/config3.json):\n",
      "   - [MEAN] 0.0208341907010427\n",
      "   - [STD] 0.016339860922586425\n",
      "   - [MAX] 0.10378701842985763\n",
      "   - [MIN] 1.9434061694763793e-05\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from Environment import Environment\n",
    "from Model.Evaluator.GraphEvaluator import GraphEvaluator\n",
    "from Model.Evaluator.Baseline import Baseline\n",
    "from Model.Evaluator.OneStepEvaluator import OneStepEvaluator\n",
    "from Learner.BruteForce import *\n",
    "from Model.Product import *\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# ==== PARAMETERS TO CHANGE ====\n",
    "config_path = \"./Configs/config3.json\"\n",
    "RANDOM_ARM = False\n",
    "n_experiments = 100\n",
    "# ==============================\n",
    "\n",
    "f = open(config_path)\n",
    "config = json.load(f)\n",
    "f.close()\n",
    "\n",
    "user_means = []\n",
    "conf_classes = config[\"classes\"]\n",
    "for uc in conf_classes:\n",
    "  user_means.append(uc[\"usersMean\"])\n",
    "class_weights = np.array(user_means) / np.array(user_means).sum()\n",
    "\n",
    "env = Environment(config_path=config_path)\n",
    "marginsPerPrice = config[\"margins\"]\n",
    "num_prods = len(config[\"margins\"])\n",
    "num_prices = len(config[\"margins\"][0])\n",
    "\n",
    "evaluatorEnvDifference = []\n",
    "bf = BruteForce(num_prices=num_prices, num_products=num_prods)\n",
    "for i in tqdm(range(0, num_prices**num_prods)):\n",
    "  arm = bf.pull_arm() \n",
    "  margins = [marginsPerPrice[i][arm[i]] for i in range(0,len(arm))]\n",
    "  # print(margins)\n",
    "  obtained_margins = []\n",
    "\n",
    "  conf_classes = config[\"classes\"]\n",
    "  evaluators_rews = []\n",
    "  for uc in conf_classes:\n",
    "      armConvRates = [uc[\"conversionRates\"][i][arm[i]] for i in range(0,len(arm))]\n",
    "      productList = [Product(int(key), uc[\"secondary\"][key]) for key in uc[\"secondary\"]]\n",
    "      eval = GraphEvaluator(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                  alphas=uc[\"alphas\"], margins=margins, units_mean=uc[\"actualUnitsMean\"], convert_units=False, verbose=False)\n",
    "      evaluators_rews.append(eval.computeMargin())\n",
    "      baseline = Baseline(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                  alphas=uc[\"alphas\"], margins=margins, units_mean=uc[\"actualUnitsMean\"], convert_units=False, verbose=False)\n",
    "      oneStep = OneStepEvaluator(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                  alphas=uc[\"alphas\"], margins=margins, units_mean=uc[\"actualUnitsMean\"], verbose=False)\n",
    "\n",
    "  env.setPriceLevels(arm)\n",
    "  for i in range(0,n_experiments):\n",
    "    inters = env.round()\n",
    "    total = 0\n",
    "    for inter in inters:\n",
    "      total += inter.linearizeMargin(marginsPerPrice)\n",
    "      obtained_margins.append(inter.linearizeMargin(marginsPerPrice))\n",
    "    total = total / len(inters)\n",
    "  \n",
    "  environmentMean = np.array(obtained_margins).mean()\n",
    "  evaluatorMeanByClass = np.multiply(evaluators_rews, class_weights).sum()\n",
    "  # Percentage error of graph eval from environment\n",
    "  evaluatorEnvDifference.append(abs(environmentMean - evaluatorMeanByClass) / environmentMean)\n",
    "\n",
    "clear_output(wait=True)\n",
    "evaluatorEnvDifference = np.array(evaluatorEnvDifference)\n",
    "print(\"PERCENTAGE ERROR OF GRAPH EVALUATOR FROM ENVIRONMENT ({}):\".format(config_path))\n",
    "print(\"   - [MEAN] {}\".format(evaluatorEnvDifference.mean()))\n",
    "print(\"   - [STD] {}\".format(evaluatorEnvDifference.std()))\n",
    "print(\"   - [MAX] {}\".format(evaluatorEnvDifference.max()))\n",
    "print(\"   - [MIN] {}\".format(evaluatorEnvDifference.min()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visiting probability computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Evaluator vs Environment visiting probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIFFERENCE FROM ENVIRONMENT AND GE VISITING PROBABILITY, ARM [3 0 3 1 1] (./Configs/config3.json):\n",
      "   - [ENV] [0.30884901 0.36340768 0.32757561 0.2032534  0.225334  ]\n",
      "      - [STARTING 0] [1.         0.06621221 0.07291725 0.00502878 0.0101693 ]\n",
      "      - [STARTING 1] [0.00727802 1.         0.29067294 0.03459859 0.1231665 ]\n",
      "      - [STARTING 2] [0.01129944 0.02522795 1.         0.04609274 0.03753426]\n",
      "      - [STARTING 3] [0.21655659 0.15481921 0.06039404 1.         0.22428076]\n",
      "      - [STARTING 4] [0.03905066 0.64893677 0.18880099 0.1827414  1.        ]\n",
      "\n",
      "   - [G/E CLASS 0] [0.50951586 0.44942762 0.18946036 0.05136863 0.08975355]\n",
      "      - [STARTING 0] [1.         0.05103401 0.061328   0.00370889 0.00782575]\n",
      "      - [STARTING 1] [0.0060145  1.         0.28012485 0.03129359 0.12093545]\n",
      "      - [STARTING 2] [0.00857623 0.02301244 1.         0.04451584 0.03581747]\n",
      "      - [STARTING 3] [0.192      0.13574053 0.04683409 1.         0.20112673]\n",
      "      - [STARTING 4] [0.03356705 0.63059674 0.17804652 0.17387059 1.        ]\n",
      "   - [G/E CLASS 1] [0.11139883 0.28161958 0.48088646 0.31959554 0.32104673]\n",
      "      - [STARTING 0] [1.         0.0511817  0.061328   0.00388459 0.00782575]\n",
      "      - [STARTING 1] [0.00656637 1.         0.28014269 0.03416005 0.12093545]\n",
      "      - [STARTING 2] [0.00870426 0.0262304  1.         0.04516096 0.03581747]\n",
      "      - [STARTING 3] [0.192      0.15375726 0.05182764 1.         0.20112673]\n",
      "      - [STARTING 4] [0.03835521 0.7205161  0.20342407 0.19851571 1.        ]\n",
      "   - [G/E CLASS 2] [0.28679395 0.39771896 0.36149018 0.26186545 0.32516808]\n",
      "      - [STARTING 0] [1.         0.15554401 0.185088   0.01957619 0.03509936]\n",
      "      - [STARTING 1] [0.01564897 1.         0.32060643 0.04649886 0.15129935]\n",
      "      - [STARTING 2] [0.02951667 0.04919943 1.         0.08741888 0.08290555]\n",
      "      - [STARTING 3] [0.336      0.24051286 0.1212854  1.         0.35653614]\n",
      "      - [STARTING 4] [0.05280413 0.5433385  0.18047108 0.15583334 1.        ]\n",
      "\n",
      "   - [G/E TOTAL] [0.30707686 0.37012294 0.33893295 0.196394   0.22250985]\n",
      "\n",
      "PERFORMANCE INDEX => [0.00177215 0.00671526 0.01135734 0.0068594  0.00282416] => 0.005905662224066616\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from Environment import Environment\n",
    "from Model.Evaluator.GraphEvaluator import GraphEvaluator\n",
    "from Model.Evaluator.Baseline import Baseline\n",
    "from Model.Evaluator.OneStepEvaluator import OneStepEvaluator\n",
    "from Learner.BruteForce import *\n",
    "from Model.Product import *\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# ==== PARAMETERS TO CHANGE ====\n",
    "config_path = \"./Configs/config3.json\"\n",
    "RANDOM_ARM = True\n",
    "arm = [0, 0, 0, 0, 0]\n",
    "n_experiments = 250\n",
    "# ==============================\n",
    "\n",
    "f = open(config_path)\n",
    "config = json.load(f)\n",
    "f.close()\n",
    "\n",
    "env = Environment(config_path=config_path)\n",
    "marginsPerPrice = config[\"margins\"]\n",
    "num_prods = len(config[\"margins\"])\n",
    "num_prices = len(config[\"margins\"][0])\n",
    "\n",
    "if RANDOM_ARM:\n",
    "    arm = np.floor(np.random.rand(len(marginsPerPrice)) * len(marginsPerPrice[0]))\n",
    "    arm = np.array(arm.tolist(), dtype=int)\n",
    "env.setPriceLevels(arm)\n",
    "\n",
    "cumulative_visits = np.zeros(num_prods)\n",
    "cumulative_interactions = 0\n",
    "for i in tqdm(range(0,n_experiments)):\n",
    "    interactions = env.round()\n",
    "    cumulative_interactions += len(interactions)\n",
    "    for inter in interactions:\n",
    "        cumulative_visits = cumulative_visits + inter.linearizeVisits()\n",
    "clear_output(wait=True)\n",
    "\n",
    "environment_probs = cumulative_visits / cumulative_interactions\n",
    "print(\"DIFFERENCE FROM ENVIRONMENT AND GE VISITING PROBABILITY, ARM {} ({}):\".format(arm, config_path))\n",
    "print(\"   - [ENV] {}\".format(environment_probs))\n",
    "\n",
    "\n",
    "for j in range(0,num_prods):\n",
    "    for k in range(0,len(config[\"classes\"])):\n",
    "        env.classes[k].alphas = np.full(num_prods, 0.000001).tolist()\n",
    "        env.classes[k].alphas[j] = 1.00004\n",
    "    cumulative_visits = np.zeros(num_prods)\n",
    "    cumulative_interactions = 0\n",
    "    for i in range(0,n_experiments):\n",
    "        interactions = env.round()\n",
    "        cumulative_interactions += len(interactions)\n",
    "        for inter in interactions:\n",
    "            cumulative_visits = cumulative_visits + inter.linearizeVisits()\n",
    "    print(\"      - [STARTING {}] {}\".format(j, cumulative_visits / cumulative_interactions))\n",
    "print(\"\")\n",
    "conf_classes = config[\"classes\"]\n",
    "i = 0\n",
    "weighted_classes = np.zeros((num_prods))\n",
    "tot_users_daily = 0\n",
    "for uc in conf_classes:\n",
    "    armConvRates = [uc[\"conversionRates\"][i][arm[i]] for i in range(0,len(arm))]\n",
    "    productList = [Product(int(key), uc[\"secondary\"][key]) for key in uc[\"secondary\"]]\n",
    "    eval = GraphEvaluator(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                alphas=uc[\"alphas\"], margins=marginsPerPrice, units_mean=uc[\"actualUnitsMean\"], convert_units=False, verbose=False)\n",
    "    visit_prob = eval.getVisitingProbability()\n",
    "    weighted_classes = weighted_classes + visit_prob * uc[\"usersMean\"]\n",
    "    tot_users_daily += uc[\"usersMean\"]\n",
    "    print(\"   - [G/E CLASS {}] {}\".format(i, visit_prob))\n",
    "    for k in range(0,num_prods):\n",
    "        print(\"      - [STARTING {}] {}\".format(k, eval.computeSingleProduct(k)))\n",
    "    i += 1\n",
    "\n",
    "print(\"\")\n",
    "ge_weighted_probs = weighted_classes / tot_users_daily\n",
    "print(\"   - [G/E TOTAL] {}\\n\".format(ge_weighted_probs))\n",
    "\n",
    "print(\"PERFORMANCE INDEX => {} => {}\".format(np.abs(ge_weighted_probs - environment_probs), np.abs(ge_weighted_probs - environment_probs).mean()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph vs Environment visiting probability total performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN ABSOLUTE ERROR FROM GRAPH EVALUATOR TO ENVIRONMENT (./Configs/config3.json):\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\School\\2021.22\\II Semestre\\Online Learning Applications\\Project\\team4_projectOLA\\Utilities.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/2021.22/II%20Semestre/Online%20Learning%20Applications/Project/team4_projectOLA/Utilities.ipynb#ch0000013?line=59'>60</a>\u001b[0m clear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/2021.22/II%20Semestre/Online%20Learning%20Applications/Project/team4_projectOLA/Utilities.ipynb#ch0000013?line=61'>62</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMEAN ABSOLUTE ERROR FROM GRAPH EVALUATOR TO ENVIRONMENT (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m):\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(config_path))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/School/2021.22/II%20Semestre/Online%20Learning%20Applications/Project/team4_projectOLA/Utilities.ipynb#ch0000013?line=62'>63</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m   - [MEAN] \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(distances_index\u001b[39m.\u001b[39;49mmean()))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/2021.22/II%20Semestre/Online%20Learning%20Applications/Project/team4_projectOLA/Utilities.ipynb#ch0000013?line=63'>64</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m   - [STD] \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(distances_index\u001b[39m.\u001b[39mstd()))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/2021.22/II%20Semestre/Online%20Learning%20Applications/Project/team4_projectOLA/Utilities.ipynb#ch0000013?line=64'>65</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m   - [MAX] \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(distances_index\u001b[39m.\u001b[39mmax()))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'mean'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from Environment import Environment\n",
    "from Model.Evaluator.GraphEvaluator import GraphEvaluator\n",
    "from Model.Evaluator.Baseline import Baseline\n",
    "from Model.Evaluator.OneStepEvaluator import OneStepEvaluator\n",
    "from Learner.BruteForce import *\n",
    "from Model.Product import *\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# ==== PARAMETERS TO CHANGE ====\n",
    "config_path = \"./Configs/config3.json\"\n",
    "n_experiments = 100\n",
    "# ==============================\n",
    "\n",
    "f = open(config_path)\n",
    "config = json.load(f)\n",
    "f.close()\n",
    "\n",
    "env = Environment(config_path=config_path)\n",
    "marginsPerPrice = config[\"margins\"]\n",
    "num_prods = len(config[\"margins\"])\n",
    "num_prices = len(config[\"margins\"][0])\n",
    "\n",
    "distances_index = []\n",
    "for i in tqdm(range(0, num_prices**num_prods)):\n",
    "    arm = bf.pull_arm() \n",
    "    env.setPriceLevels(arm)\n",
    "\n",
    "    cumulative_visits = np.zeros(num_prods)\n",
    "    cumulative_interactions = 0\n",
    "    for i in range(0,n_experiments):\n",
    "        interactions = env.round()\n",
    "        cumulative_interactions += len(interactions)\n",
    "        for inter in interactions:\n",
    "            cumulative_visits = cumulative_visits + inter.linearizeVisits()\n",
    "    \n",
    "\n",
    "    environment_probs = cumulative_visits / cumulative_interactions\n",
    "\n",
    "    conf_classes = config[\"classes\"]\n",
    "    i = 0\n",
    "    weighted_classes = np.zeros((num_prods))\n",
    "    tot_users_daily = 0\n",
    "    for uc in conf_classes:\n",
    "        armConvRates = [uc[\"conversionRates\"][i][arm[i]] for i in range(0,len(arm))]\n",
    "        productList = [Product(int(key), uc[\"secondary\"][key]) for key in uc[\"secondary\"]]\n",
    "        eval = GraphEvaluator(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                    alphas=uc[\"alphas\"], margins=marginsPerPrice, units_mean=uc[\"actualUnitsMean\"], convert_units=False, verbose=False)\n",
    "        visit_prob = eval.getVisitingProbability()\n",
    "        weighted_classes = weighted_classes + visit_prob * uc[\"usersMean\"]\n",
    "        tot_users_daily += uc[\"usersMean\"]\n",
    "        i += 1\n",
    "\n",
    "    ge_weighted_probs = weighted_classes / tot_users_daily\n",
    "\n",
    "    distances_index.append(np.abs(ge_weighted_probs - environment_probs).mean())\n",
    "\n",
    "clear_output(wait=True)\n",
    "distances_index = np.array(distances_index)\n",
    "\n",
    "print(\"MEAN ABSOLUTE ERROR OF VISITING PROBABILITY FROM GRAPH EVALUATOR TO ENVIRONMENT ({}):\".format(config_path))\n",
    "print(\"   - [MEAN] {}\".format(distances_index.mean()))\n",
    "print(\"   - [STD] {}\".format(distances_index.std()))\n",
    "print(\"   - [MAX] {}\".format(distances_index.max()))\n",
    "print(\"   - [MIN] {}\".format(distances_index.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN ABSOLUTE ERROR FROM GRAPH EVALUATOR TO ENVIRONMENT (./Configs/config3.json):\n",
      "   - [MEAN] 0.015544944923210742\n",
      "   - [STD] 0.002981508112788395\n",
      "   - [MAX] 0.026192905821785472\n",
      "   - [MIN] 0.007054892092087162\n"
     ]
    }
   ],
   "source": [
    "distances_index = np.array(distances_index)\n",
    "\n",
    "print(\"MEAN ABSOLUTE ERROR FROM GRAPH EVALUATOR TO ENVIRONMENT ({}):\".format(config_path))\n",
    "print(\"   - [MEAN] {}\".format(distances_index.mean()))\n",
    "print(\"   - [STD] {}\".format(distances_index.std()))\n",
    "print(\"   - [MAX] {}\".format(distances_index.max()))\n",
    "print(\"   - [MIN] {}\".format(distances_index.min()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration classes merge consistency check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MERGE USER CLASSES CHECK (./Configs/configuration4.json):\n",
      "   - [ALPHA ACTUAL] [0.27127737 0.24172072 0.15929376 0.18431449 0.14339365] \n",
      "   - [ALPHA DERIVED] [0.275, 0.2375, 0.1625, 0.18125, 0.14375] \n",
      "   - [ALPHA PERFORMANCE] 0.002914085743549738 \n",
      "\n",
      "   - [UNITS ACTUAL] [2.27701163 2.14639937 2.17684078 2.3994709  2.37880867] \n",
      "   - [UNITS DERIVED] [2.2713750000000004, 2.1505875000000003, 2.2167875, 2.426625, 2.3798625] \n",
      "   - [UNITS PERFORMANCE] 0.015595882232594694 \n",
      "\n",
      "   - [CONV RATES ACTUAL] [[0.8  0.74 0.63 0.55]\n",
      " [0.81 0.68 0.59 0.54]\n",
      " [0.9  0.77 0.66 0.58]\n",
      " [0.71 0.66 0.61 0.54]\n",
      " [0.8  0.72 0.65 0.59]] \n",
      "   - [CONV RATES DERIVED] [[0.81 0.74 0.64 0.57]\n",
      " [0.8  0.68 0.58 0.54]\n",
      " [0.9  0.74 0.63 0.57]\n",
      " [0.74 0.67 0.61 0.54]\n",
      " [0.81 0.73 0.66 0.59]] \n",
      "   - [CONV RATES PERFORMANCE] 0.011568180815482798 \n",
      "\n",
      "   - [CLICK PROB ESTIMATED 1] \n",
      "[[0.   0.58 0.   0.   0.7 ]\n",
      " [0.46 0.   0.   0.   0.35]\n",
      " [0.   0.   0.   0.72 0.66]\n",
      " [0.4  0.   0.87 0.   0.  ]\n",
      " [0.64 0.77 0.   0.   0.  ]] \n",
      "   - [CLICK PROB DERIVED] \n",
      "[[0.   0.6  0.   0.   0.72]\n",
      " [0.45 0.   0.   0.   0.45]\n",
      " [0.   0.   0.   0.75 0.68]\n",
      " [0.5  0.   0.79 0.   0.  ]\n",
      " [0.54 0.79 0.   0.   0.  ]] \n",
      "   - [CLICK PROB ESTIMATED 2] \n",
      "[[0.   0.58 0.   0.   0.7 ]\n",
      " [0.46 0.   0.   0.   0.35]\n",
      " [0.   0.   0.   0.72 0.66]\n",
      " [0.4  0.   0.87 0.   0.  ]\n",
      " [0.64 0.77 0.   0.   0.  ]]\n",
      "   - [CLICK PROB PERFORMANCE] 0.02023414218032614 \n",
      "\n",
      "  [3491. 1425. 1344. 2197. 2444.]\n",
      " [3180. 1386. 1653. 1094. 2692.]\n",
      " [[   0. 3491.    0.    0. 3180.]\n",
      " [1386.    0.    0.    0. 1425.]\n",
      " [   0.    0.    0. 1344. 1653.]\n",
      " [1094.    0. 2197.    0.    0.]\n",
      " [2444. 2692.    0.    0.    0.]]\n",
      "\n",
      "  [6002. 4113. 1861. 2537. 3822.]\n",
      " [5648. 3747. 3146. 3447. 4388.]\n",
      " [[   0. 6007.    0.    0. 5648.]\n",
      " [3747.    0.    0.    0. 4113.]\n",
      " [   0.    0.    0. 1861. 3146.]\n",
      " [3447.    0. 2537.    0.    0.]\n",
      " [3822. 4377.    0.    0.    0.]]\n"
     ]
    }
   ],
   "source": [
    "from Model.ConfigurationParametersAverage import mergeUserClasses\n",
    "from Environment import Environment\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# ==== PARAMETERS TO CHANGE ====\n",
    "CONFIG_PATH = './Configs/configuration4.json'\n",
    "n_experiments = 250\n",
    "# ==============================\n",
    "\n",
    "env = Environment(config_path=CONFIG_PATH)\n",
    "\n",
    "config = mergeUserClasses([CONFIG_PATH], False)[0]\n",
    "l = config[\"lambda_p\"]\n",
    "\n",
    "env.setPriceLevels([0,1,3,1,0])\n",
    "total_inters = 0\n",
    "total_starting = np.full(5,0)\n",
    "total_bought = np.full(5,0)\n",
    "total_units = np.full(5,0)\n",
    "total_visits = np.full(5,0)\n",
    "for i in range(0,n_experiments):\n",
    "    inters = env.round()\n",
    "    total_inters += len(inters)\n",
    "    for inter in inters:\n",
    "        total_starting = np.add(inter.linearizeStart(), total_starting)\n",
    "        total_bought = np.add(inter.linearizeBought(), total_bought)\n",
    "        total_units = np.add(inter.linearizeNumUnits(), total_units)\n",
    "        total_visits = np.add(inter.linearizeVisits(), total_visits)\n",
    "\n",
    "print(\"MERGE USER CLASSES CHECK ({}):\".format(CONFIG_PATH))\n",
    "print(\"   - [ALPHA ACTUAL] {} \".format(total_starting / total_inters))\n",
    "print(\"   - [ALPHA DERIVED] {} \".format(config[\"alphas\"]))\n",
    "print(\"   - [ALPHA PERFORMANCE] {} \\n\".format(np.abs(np.subtract(total_starting / total_inters, config[\"alphas\"])).mean()))\n",
    "\n",
    "print(\"   - [UNITS ACTUAL] {} \".format(total_units / total_bought))\n",
    "print(\"   - [UNITS DERIVED] {} \".format(config[\"actual_units_mean\"]))\n",
    "print(\"   - [UNITS PERFORMANCE] {} \\n\".format(np.abs(np.subtract(total_units / total_bought, config[\"actual_units_mean\"])).mean()))\n",
    "\n",
    "conv_rates = np.full((5,4),0, dtype=float)\n",
    "for k in range(0,4):\n",
    "    env.setPriceLevels(np.full(5,k).tolist())\n",
    "\n",
    "    total_bought = np.full(5,0)\n",
    "    total_visits = np.full(5,0)\n",
    "    for i in range(0,n_experiments):\n",
    "        inters = env.round()\n",
    "        total_inters += len(inters)\n",
    "        for inter in inters:\n",
    "            total_bought = np.add(inter.linearizeBought(), total_bought)\n",
    "            total_visits = np.add(inter.linearizeVisits(), total_visits)\n",
    "    \n",
    "    curr_rates = total_bought / total_visits\n",
    "    # print(curr_rates)\n",
    "    for i in range(0,len(curr_rates)):\n",
    "        conv_rates[i][k] = curr_rates[i]\n",
    "\n",
    "\n",
    "print(\"   - [CONV RATES ACTUAL] {} \".format(np.round(conv_rates, decimals=2)))\n",
    "print(\"   - [CONV RATES DERIVED] {} \".format(np.round(config[\"conversionRateLevels\"], decimals=2)))\n",
    "print(\"   - [CONV RATES PERFORMANCE] {} \\n\".format(np.abs(np.subtract(conv_rates, config[\"conversionRateLevels\"])).mean()))\n",
    "\n",
    "interactions = []\n",
    "env.setPriceLevels([0,1,3,1,0])\n",
    "for i in range(0,n_experiments):\n",
    "    interactions = interactions + env.round()\n",
    "secondary = config[\"productList\"]\n",
    "sec_prods = []\n",
    "for p in secondary:\n",
    "    sec_prods.append([p.getSecondaryProduct(0), p.getSecondaryProduct(1)])\n",
    "clickProbability = np.zeros((5,5))\n",
    "openedFirst = np.zeros(5)\n",
    "openedSecond = np.zeros(5)\n",
    "trialFirst = np.zeros(5)\n",
    "trialSecond = np.zeros(5)\n",
    "\n",
    "single_interactions_list = []\n",
    "for inter in interactions:\n",
    "    single_interactions_list.append(inter)\n",
    "    trialFirst = np.add(trialFirst, inter.linearizeOpenedFirstTrial())\n",
    "    trialSecond = np.add(trialSecond, inter.linearizeOpenedSecondTrial())\n",
    "\n",
    "while len(single_interactions_list) > 0:\n",
    "    p = single_interactions_list.pop()\n",
    "    openedFirst[p.product] += p.sec1Opened\n",
    "    openedSecond[p.product] += p.sec2Opened\n",
    "    # expand\n",
    "    for j in range(0, len(p.following)):\n",
    "        single_interactions_list.append(p.following[j])\n",
    "\n",
    "for i in range(0,5):\n",
    "    if trialFirst[i] > 0:\n",
    "        clickProbability[i][sec_prods[i][0]] = openedFirst[i] / trialFirst[i]\n",
    "    if trialSecond[i] > 0:\n",
    "        clickProbability[i][sec_prods[i][1]] = openedSecond[i] / trialSecond[i]\n",
    "        clickProbability[i][sec_prods[i][1]] = clickProbability[i][sec_prods[i][1]] / config[\"lambda_p\"]\n",
    "\n",
    "print(\"   - [CLICK PROB ESTIMATED 1] \\n{} \".format(np.round(clickProbability, decimals=2)))\n",
    "print(\"   - [CLICK PROB DERIVED] \\n{} \".format(np.round(config[\"click_prob\"], decimals=2)))\n",
    "\n",
    "\n",
    "prob_seen_given_bought_inverted = np.zeros((5, 5), dtype=float)\n",
    "        \n",
    "for prod in config[\"productList\"]:\n",
    "    primary = prod.getProductNumber()\n",
    "    sec_list = prod.getSecondaryProductList()\n",
    "    prob_seen_given_bought_inverted[primary][sec_list[0]] = 1\n",
    "    prob_seen_given_bought_inverted[primary][sec_list[1]] = 1 / l # this is lambda not one\n",
    "\n",
    "opening_cumulative = np.zeros((5, 5), dtype=float)\n",
    "max_possible_opening_cumulative = np.zeros((5, 5), dtype=float)\n",
    "for inter in interactions:\n",
    "    opening_cumulative = np.add(opening_cumulative, inter.linearizeSecondaryOpening())\n",
    "    max_possible_opening_cumulative = np.add(max_possible_opening_cumulative, inter.linearizePossibleSecondaryOpening())\n",
    "\n",
    "opening_prob_given_bought = np.divide(opening_cumulative, max_possible_opening_cumulative, \n",
    "                        out=np.full_like(opening_cumulative, 0), where=max_possible_opening_cumulative!=0)\n",
    "        \n",
    "opening_prob_given_seen = opening_prob_given_bought * prob_seen_given_bought_inverted\n",
    "print(\"   - [CLICK PROB ESTIMATED 2] \\n{}\".format(np.round(opening_prob_given_seen, decimals=2)))\n",
    "print(\"   - [CLICK PROB PERFORMANCE] {} \".format(np.abs(np.subtract(clickProbability, config[\"click_prob\"])).mean()))\n",
    "\n",
    "print(\"\\n \", openedFirst)\n",
    "print(\"\", openedSecond)\n",
    "print(\"\", opening_cumulative)\n",
    "\n",
    "print(\"\\n \", trialFirst)\n",
    "print(\"\", trialSecond)\n",
    "print(\"\", max_possible_opening_cumulative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration clairevoyancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming units shape in units mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE TRANSFORMATION:\n",
      "   - [DISTRO] [0.94, 1.45, 1.2, 2.0, 1.5]\n",
      "   - [SAMPLING] [1.5321, 1.9754, 1.7497, 2.504, 2.0233]\n",
      "   - [GAMMA SCIPY] [1.527, 1.9716, 1.7454, 2.4968, 2.0175]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import gamma\n",
    "\n",
    "units_mean = [0.94, 1.45, 1.2, 2.0, 1.5]\n",
    "actual_means = []\n",
    "for i in range(0,len(units_mean)):\n",
    "    empiric_mean = np.ceil(np.random.gamma(units_mean[i], 1, size=1000000)).mean()\n",
    "    actual_means.append(int(empiric_mean*10000) / 10000)\n",
    "print(\"SHAPE TRANSFORMATION:\")\n",
    "print(\"   - [DISTRO] {}\".format(units_mean))\n",
    "print(\"   - [SAMPLING] {}\".format(actual_means))\n",
    "\n",
    "actual_means = []\n",
    "for i in range(0,len(units_mean)):\n",
    "    # empiric_mean = np.ceil(np.random.gamma(units_mean[i], 1, size=1000000)).mean()\n",
    "    # New method using cumulative distribution, difference empiric and theoretic < 0.01\n",
    "    significant = True\n",
    "    theoretic_mean = 0\n",
    "    num = 1\n",
    "    while significant:\n",
    "        t = (gamma.cdf(num, a=units_mean[i]) - gamma.cdf(num - 1, a=units_mean[i])) * num\n",
    "        theoretic_mean += t\n",
    "        num += 1\n",
    "        if t < 0.01:\n",
    "            significant = False\n",
    "    #print(num)\n",
    "    actual_means.append(int(theoretic_mean*10000) / 10000)\n",
    "#print(actual_means)\n",
    "units_mean = np.array(actual_means)\n",
    "print(\"   - [GAMMA SCIPY] {}\".format(actual_means))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the best arm for each class by brute force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRUTE FORCE OF CONFIG ./Configs/configuration6.json CLASSES:\n",
      "   - [CLASS 0] Optimal arm is [3, 3, 3, 3, 3] with margin 86.4\n",
      "   - [CLASS 1] Optimal arm is [0, 0, 0, 0, 0] with margin 2.1285000000000003\n",
      "   - [CLASS 2] Optimal arm is [2, 2, 2, 2, 2] with margin 16.968000000000004\n",
      "\n",
      "The optimal weighted mean expected margin given the mean daily users [10 40 25] is 18.3112\n",
      "\n",
      "Which arm among the best ones gives the better results in non contextual optmization?\n",
      "   - [ARM [3, 3, 3, 3, 3]] Class-weighted expected margin is 12.504166666666668\n",
      "   - [ARM [0, 0, 0, 0, 0]] Class-weighted expected margin is 2.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 27/1024 [00:00<00:03, 262.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - [ARM [2, 2, 2, 2, 2]] Class-weighted expected margin is 8.590666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 273.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRUTE FORCE BY WEIGHTING CLASSES REWARDS:\n",
      "   - [THEORY] Optimal arm is [3, 3, 3, 2, 3] with margin 14.373466666666669\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from Environment import Environment\n",
    "import numpy as np\n",
    "from Learner.BruteForce import *\n",
    "from Model.UserClass import *\n",
    "from Model.Product import *\n",
    "from Model.GraphProbabilities import *\n",
    "from Model.Evaluator.GraphEvaluator import GraphEvaluator\n",
    "from Model.Evaluator.Baseline import Baseline\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "\n",
    "# ==== PARAMETERS TO CHANGE ====\n",
    "CONFIG_PATH = './Configs/configuration6.json'\n",
    "# ==============================\n",
    "\n",
    "\n",
    "f = open(CONFIG_PATH)\n",
    "config = json.load(f)\n",
    "f.close()\n",
    "\n",
    "opt_arms = []\n",
    "opt_margins = []\n",
    "daily_users = []\n",
    "print(\"Starting the analysis ...\\n\")\n",
    "for k in range(0, len(config[\"classes\"])):\n",
    "    uc = config[\"classes\"][k]\n",
    "\n",
    "    productList = [Product(int(key), uc[\"secondary\"][key]) for key in uc[\"secondary\"]]\n",
    "\n",
    "    conversionRateLevels = uc[\"conversionRates\"]\n",
    "    marginsPerPrice = config[\"margins\"]\n",
    "    click_prob = np.array(uc[\"clickProbability\"])\n",
    "    lambda_p = uc[\"lambda\"]\n",
    "    alphas = uc[\"alphas\"]\n",
    "    units_mean = uc[\"actualUnitsMean\"]\n",
    "    # Early transform for efficiency reason\n",
    "    # actual_means = []\n",
    "    # for i in range(0,len(units_mean)):\n",
    "    #    empiric_mean = np.ceil(np.random.gamma(units_mean[i], 1, size=1000000)).mean()\n",
    "    #     actual_means.append(int(empiric_mean*100) / 100)\n",
    "    # units_mean = actual_means\n",
    "\n",
    "    daily_users.append(uc[\"usersMean\"])\n",
    "    num_prices = len(conversionRateLevels[0])\n",
    "    num_prods = len(alphas)\n",
    "\n",
    "    print(\"Brute forcing class {}\".format(k))\n",
    "    bf = BruteForce(num_prices=num_prices, num_products=num_prods)\n",
    "    for i in tqdm(range(0, num_prices**num_prods)):\n",
    "        pulledArm = bf.pull_arm()\n",
    "        margins = []\n",
    "        convRates = []\n",
    "        for k in range(0,len(pulledArm)):\n",
    "            margins.append(marginsPerPrice[k][pulledArm[k]])\n",
    "            convRates.append(conversionRateLevels[k][pulledArm[k]])\n",
    "\n",
    "        price_configuration_margin = 0\n",
    "        eval = GraphEvaluator(products_list=productList, click_prob_matrix=click_prob, lambda_prob=lambda_p, conversion_rates=convRates,\n",
    "                        alphas=alphas, margins=margins, units_mean=units_mean, convert_units=False, verbose=False)\n",
    "        eval2 = Baseline(products_list=productList, click_prob_matrix=click_prob, lambda_prob=lambda_p, conversion_rates=convRates,\n",
    "                        alphas=alphas, margins=margins, units_mean=units_mean, convert_units=False, verbose=False)\n",
    "\n",
    "        overall_margin = eval.computeMargin()\n",
    "        baseline = eval2.computeMargin()\n",
    "        # print(\"Configuration {}; ConvRates {}; Margins {}; Overall Margin {}; Baseline {}\".format(pulledArm,convRates,margins,int(overall_margin*100)/100,int(baseline*100)/100))\n",
    "        # if overall_margin < baseline:\n",
    "            # print(\"VAFFANCULOOOOO {} - {} = {}\".format(overall_margin,baseline,overall_margin-baseline))\n",
    "        bf.update(overall_margin)\n",
    "\n",
    "    opt_arms.append(bf.get_optima())\n",
    "    opt_margins.append(bf.get_optima_margin())\n",
    "clear_output(wait=True)\n",
    "print(\"BRUTE FORCE OF CONFIG {} CLASSES:\".format(CONFIG_PATH))\n",
    "for i in range(0,len(opt_arms)):\n",
    "    print(\"   - [CLASS {}] Optimal arm is {} with margin {}\".format(i,opt_arms[i], opt_margins[i]))\n",
    "\n",
    "daily_users = np.array(daily_users)\n",
    "classes_weights = daily_users / daily_users.sum()\n",
    "opt_margins = np.array(opt_margins)\n",
    "print(\"\\nThe optimal weighted mean expected margin given the mean daily users {} is {}\".format(daily_users, np.multiply(classes_weights, opt_margins).sum()))\n",
    "\n",
    "# Best single arm possible\n",
    "print(\"\\nWhich arm among the best ones gives the better results in non contextual optmization?\")\n",
    "equal_arm_rew = []\n",
    "for i in range(0,len(opt_arms)):\n",
    "    arm = opt_arms[i]\n",
    "    class_rewards = []\n",
    "    for k in range(0, len(config[\"classes\"])):\n",
    "        uc = config[\"classes\"][k]\n",
    "        productList = [Product(int(key), uc[\"secondary\"][key]) for key in uc[\"secondary\"]]\n",
    "        conversionRateLevels = uc[\"conversionRates\"]\n",
    "        marginsPerPrice = config[\"margins\"]\n",
    "        click_prob = np.array(uc[\"clickProbability\"])\n",
    "        lambda_p = uc[\"lambda\"]\n",
    "        alphas = uc[\"alphas\"]\n",
    "        units_mean = uc[\"unitsShape\"]\n",
    "        num_prices = len(conversionRateLevels[0])\n",
    "        num_prods = len(alphas)\n",
    "\n",
    "        pulledArm = arm\n",
    "        margins = []\n",
    "        convRates = []\n",
    "        for k in range(0,len(pulledArm)):\n",
    "            margins.append(marginsPerPrice[k][pulledArm[k]])\n",
    "            convRates.append(conversionRateLevels[k][pulledArm[k]])\n",
    "\n",
    "        eval = GraphEvaluator(products_list=productList, click_prob_matrix=click_prob, lambda_prob=lambda_p, conversion_rates=convRates,\n",
    "                        alphas=alphas, margins=margins, units_mean=units_mean, verbose=False)\n",
    "        eval2 = Baseline(products_list=productList, click_prob_matrix=click_prob, lambda_prob=lambda_p, conversion_rates=convRates,\n",
    "                        alphas=alphas, margins=margins, units_mean=units_mean, verbose=False)\n",
    "                    \n",
    "        class_rewards.append(eval.computeMargin())\n",
    "    \n",
    "    weighted_reward = np.multiply(classes_weights, np.array(class_rewards)).sum()\n",
    "    equal_arm_rew.append(weighted_reward)\n",
    "    if class_rewards[i] < eval2.computeMargin():\n",
    "        print(\"   - [ARM {}] Class-weighted expected margin is {}, but baseline is greater than weighted\".format(arm, weighted_reward))\n",
    "    else:\n",
    "        print(\"   - [ARM {}] Class-weighted expected margin is {}\".format(arm, weighted_reward))\n",
    "\n",
    "\n",
    "user_means = []\n",
    "conf_classes = config[\"classes\"]\n",
    "for uc in conf_classes:\n",
    "  user_means.append(uc[\"usersMean\"])\n",
    "class_weights = np.array(user_means) / np.array(user_means).sum()\n",
    "\n",
    "bf = BruteForce(num_prices=num_prices, num_products=num_prods)\n",
    "for i in tqdm(range(0, num_prices**num_prods)):\n",
    "    arm = bf.pull_arm() \n",
    "    margins = [marginsPerPrice[i][arm[i]] for i in range(0,len(arm))]\n",
    "\n",
    "    obtained_margins = []\n",
    "\n",
    "    conf_classes = config[\"classes\"]\n",
    "    evaluators_rews = []\n",
    "    for uc in conf_classes:\n",
    "        armConvRates = [uc[\"conversionRates\"][i][arm[i]] for i in range(0,len(arm))]\n",
    "        productList = [Product(int(key), uc[\"secondary\"][key]) for key in uc[\"secondary\"]]\n",
    "        eval = GraphEvaluator(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                    alphas=uc[\"alphas\"], margins=margins, units_mean=uc[\"actualUnitsMean\"], convert_units=False, verbose=False)\n",
    "        evaluators_rews.append(eval.computeMargin())    \n",
    "\n",
    "    evaluatorMeanByClass = np.multiply(evaluators_rews, class_weights).sum()\n",
    "    bf.update(evaluatorMeanByClass)\n",
    "\n",
    "print(\"BRUTE FORCE BY WEIGHTING CLASSES REWARDS:\".format(CONFIG_PATH))\n",
    "print(\"   - [THEORY] Optimal arm is {} with margin {}\".format(bf.get_optima(), bf.get_optima_margin()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute best non stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRUTE FORCE BY WEIGHTING CLASSES REWARDS FOR EACH CHANGE:\n",
      "   - [TIME 0] Optimal arm is [0, 0, 0, 0, 0] with margin 8.466090690810342\n",
      "   - [TIME 30] Optimal arm is [0, 2, 2, 3, 3] with margin 55.42822572144698\n",
      "   - [TIME 50] Optimal arm is [0, 2, 2, 3, 3] with margin 88.33533076102285\n",
      "   - [TIME 70] Optimal arm is [0, 2, 2, 3, 3] with margin 113.20408303272983\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from Environment import Environment\n",
    "import numpy as np\n",
    "from Learner.BruteForce import *\n",
    "from Model.UserClass import *\n",
    "from Model.Product import *\n",
    "from Model.GraphProbabilities import *\n",
    "from Model.Evaluator.GraphEvaluator import GraphEvaluator\n",
    "from Model.Evaluator.MultiClassEvaluator import MultiClassEvaluator\n",
    "from Model.Evaluator.Baseline import Baseline\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# ==== PARAMETERS TO CHANGE ====\n",
    "CONFIG_PATH = './Configs/ns_config5.json'\n",
    "# ==============================\n",
    "\n",
    "\n",
    "f = open(CONFIG_PATH)\n",
    "config = json.load(f)\n",
    "f.close()\n",
    "\n",
    "num_prices = len(config[\"margins\"][0])\n",
    "num_prods = len(config[\"margins\"])\n",
    "\n",
    "# Computing when there will be some changes\n",
    "opt_time_start = [0]\n",
    "changes = []\n",
    "for uc in config[\"classes\"]:\n",
    "    if \"change\" in uc:\n",
    "        changes.append(uc[\"change\"])\n",
    "changes = sorted(changes, key=lambda x: x['step'])\n",
    "for ch in changes:\n",
    "    opt_time_start.append(ch[\"step\"])\n",
    "\n",
    "\n",
    "# Computing class weights\n",
    "user_means = []\n",
    "conf_classes = config[\"classes\"]\n",
    "for uc in conf_classes:\n",
    "  user_means.append(uc[\"usersMean\"])\n",
    "class_weights = np.array(user_means) / np.array(user_means).sum()\n",
    "\n",
    "# Compuring for each change the best by brute forcing\n",
    "print(\"BRUTE FORCE BY WEIGHTING CLASSES REWARDS FOR EACH CHANGE:\".format(CONFIG_PATH))\n",
    "mce = MultiClassEvaluator(CONFIG_PATH)\n",
    "for time in opt_time_start:\n",
    "    bf = BruteForce(num_prices=num_prices, num_products=num_prods)\n",
    "    for i in range(0, num_prices**num_prods):\n",
    "        arm = bf.pull_arm() \n",
    "\n",
    "        weightedRewardAtTime = mce.computeMargin(arm, time=time)\n",
    "        bf.update(weightedRewardAtTime)\n",
    "\n",
    "    print(\"   - [TIME {}] Optimal arm is {} with margin {}\".format(time, bf.get_optima(), bf.get_optima_margin()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4da58a1a6a2e0ab4cf527f1d9d1806c110b7bee12e602e51dd8d47f6f506ad3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
