{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check wheter expected interaction reward matches with environment reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SINGLE ITERATION/SESSION REWARDS FOR CONFIG [0 1 2 3 1]:\n",
      "   - [EMPIRICAL] Mean reward (500 experiments from env): 8.250265764001567\n",
      "\n",
      "   - [THEORY CLASS 0] Graph expected reward: 7.1512899999999995\n",
      "   - [THEORY CLASS 0] Baseline expected reward: 7.1512899999999995\n",
      "   - [THEORY CLASS 0] One-Step expected reward: 6.43\n",
      "\n",
      "   - [THEORY CLASS 1] Graph expected reward: 8.094100000000001\n",
      "   - [THEORY CLASS 1] Baseline expected reward: 8.094100000000001\n",
      "   - [THEORY CLASS 1] One-Step expected reward: 7.4\n",
      "\n",
      "   - [THEORY CLASS 2] Graph expected reward: 11.696\n",
      "   - [THEORY CLASS 2] Baseline expected reward: 11.696\n",
      "   - [THEORY CLASS 2] One-Step expected reward: 11.0\n",
      "\n",
      "   - [THEORETICAL] Graph expected reward weighted by [30 30 10]: 8.204595714285716\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from Environment import Environment\n",
    "from Model.Evaluator.GraphEvaluator import GraphEvaluator\n",
    "from Model.Evaluator.Baseline import Baseline\n",
    "from Model.Evaluator.OneStepEvaluator import OneStepEvaluator\n",
    "\n",
    "from Model.Product import *\n",
    "import numpy as np\n",
    "\n",
    "# ==== PARAMETERS TO CHANGE ====\n",
    "config_path = \"./Configs/config2.json\"\n",
    "RANDOM_ARM = True\n",
    "arm = [1, 1, 1, 1, 1]\n",
    "n_experiments = 500\n",
    "# ==============================\n",
    "\n",
    "f = open(config_path)\n",
    "config = json.load(f)\n",
    "f.close()\n",
    "\n",
    "env = Environment(config_path=config_path)\n",
    "marginsPerPrice = config[\"margins\"]\n",
    "\n",
    "if RANDOM_ARM:\n",
    "    arm = np.floor(np.random.rand(len(marginsPerPrice)) * len(marginsPerPrice[0]))\n",
    "    arm = np.array(arm.tolist(), dtype=int)\n",
    "\n",
    "margins = [marginsPerPrice[i][arm[i]] for i in range(0,len(arm))]\n",
    "# print(margins)\n",
    "obtained_margins = []\n",
    "\n",
    "conf_classes = config[\"classes\"]\n",
    "user_means = []\n",
    "evaluators = []\n",
    "for uc in conf_classes:\n",
    "    armConvRates = [uc[\"conversionRates\"][i][arm[i]] for i in range(0,len(arm))]\n",
    "    productList = [Product(int(key), uc[\"secondary\"][key]) for key in uc[\"secondary\"]]\n",
    "    eval = GraphEvaluator(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                alphas=uc[\"alphas\"], margins=margins, units_mean=uc[\"unitsShape\"], convert_units=True, verbose=False)\n",
    "    baseline = Baseline(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                alphas=uc[\"alphas\"], margins=margins, units_mean=uc[\"unitsShape\"], convert_units=True, verbose=False)\n",
    "    oneStep = OneStepEvaluator(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                alphas=uc[\"alphas\"], margins=margins, units_mean=uc[\"unitsShape\"], verbose=False)\n",
    "    evaluators.append((eval,baseline,oneStep))\n",
    "    user_means.append(uc[\"usersMean\"])\n",
    "user_means = np.array(user_means)\n",
    "\n",
    "env.setPriceLevels(arm)\n",
    "for i in range(0,n_experiments):\n",
    "  inters = env.round()\n",
    "  total = 0\n",
    "  for inter in inters:\n",
    "    total += inter.linearizeMargin(marginsPerPrice)\n",
    "    obtained_margins.append(inter.linearizeMargin(marginsPerPrice))\n",
    "  total = total / len(inters)\n",
    "  # obtained_margins.append(total)\n",
    "\n",
    "print(\"SINGLE ITERATION/SESSION REWARDS FOR CONFIG {}:\".format(arm))\n",
    "print(\"   - [EMPIRICAL] Mean reward ({} experiments from env): {}\\n\".format(n_experiments, np.array(obtained_margins).mean()))\n",
    "\n",
    "i = 0\n",
    "ge_margins = []\n",
    "for ev_group in evaluators:\n",
    "  ge_result = ev_group[0].computeMargin()\n",
    "  ge_margins.append(ge_result)\n",
    "  print(\"   - [THEORY CLASS {}] Graph expected reward: {}\".format(i, ge_result))\n",
    "  print(\"   - [THEORY CLASS {}] Baseline expected reward: {}\".format(i, ev_group[1].computeMargin()))\n",
    "  print(\"   - [THEORY CLASS {}] One-Step expected reward: {}\\n\".format(i, ev_group[2].computeMargin()))\n",
    "  i += 1\n",
    "\n",
    "print(\"   - [THEORETICAL] Graph expected reward weighted by {}: {}\".format(user_means, np.multiply(user_means, ge_margins).sum() / user_means.sum() ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class for config evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'obtained_margins' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\School\\2021.22\\II Semestre\\Online Learning Applications\\Project\\team4_projectOLA\\Utilities.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/2021.22/II%20Semestre/Online%20Learning%20Applications/Project/team4_projectOLA/Utilities.ipynb#ch0000016?line=34'>35</a>\u001b[0m \u001b[39mfor\u001b[39;00m inter \u001b[39min\u001b[39;00m inters:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/2021.22/II%20Semestre/Online%20Learning%20Applications/Project/team4_projectOLA/Utilities.ipynb#ch0000016?line=35'>36</a>\u001b[0m   total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m inter\u001b[39m.\u001b[39mlinearizeMargin(marginsPerPrice)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/School/2021.22/II%20Semestre/Online%20Learning%20Applications/Project/team4_projectOLA/Utilities.ipynb#ch0000016?line=36'>37</a>\u001b[0m   obtained_margins\u001b[39m.\u001b[39mappend(inter\u001b[39m.\u001b[39mlinearizeMargin(marginsPerPrice))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/2021.22/II%20Semestre/Online%20Learning%20Applications/Project/team4_projectOLA/Utilities.ipynb#ch0000016?line=37'>38</a>\u001b[0m total \u001b[39m=\u001b[39m total \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(inters)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/2021.22/II%20Semestre/Online%20Learning%20Applications/Project/team4_projectOLA/Utilities.ipynb#ch0000016?line=38'>39</a>\u001b[0m \u001b[39m# obtained_margins.append(total)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'obtained_margins' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from Environment import Environment\n",
    "from Model.Evaluator.MultiClassEvaluator import MultiClassEvaluator\n",
    "from Model.Product import *\n",
    "import numpy as np\n",
    "\n",
    "# ==== PARAMETERS TO CHANGE ====\n",
    "config_path = \"./Configs/config2.json\"\n",
    "RANDOM_ARM = True\n",
    "arm = [1, 1, 1, 1, 1]\n",
    "n_experiments = 500\n",
    "# ==============================\n",
    "\n",
    "NUM_PRODS = len(arm)\n",
    "mce = MultiClassEvaluator(config_path=config_path)\n",
    "\n",
    "f = open(config_path)\n",
    "config = json.load(f)\n",
    "f.close()\n",
    "\n",
    "env = Environment(config_path=config_path)\n",
    "marginsPerPrice = config[\"margins\"]\n",
    "NUM_PRODS = len(marginsPerPrice)\n",
    "NUM_PRICES = len(marginsPerPrice[0])\n",
    "\n",
    "\n",
    "if RANDOM_ARM:\n",
    "    arm = np.floor(np.random.rand(NUM_PRODS) * NUM_PRICES)\n",
    "    arm = np.array(arm.tolist(), dtype=int)\n",
    "\n",
    "env.setPriceLevels(arm)\n",
    "obtained_margins = []\n",
    "for i in range(0,n_experiments):\n",
    "  inters = env.round()\n",
    "  total = 0\n",
    "  for inter in inters:\n",
    "    total += inter.linearizeMargin(marginsPerPrice)\n",
    "    obtained_margins.append(inter.linearizeMargin(marginsPerPrice))\n",
    "  total = total / len(inters)\n",
    "  # obtained_margins.append(total)\n",
    "\n",
    "print(\"SINGLE ITERATION/SESSION REWARDS FOR CONFIG {}:\".format(arm))\n",
    "print(\"   - [EMPIRICAL] Mean reward ({} experiments from env): {}\\n\".format(n_experiments, np.array(obtained_margins).mean()))\n",
    "print(\"   - [THEORETICAL] Graph expected reward weighted by MultiClassEvaluator: {}\".format(mce.computeMargin(arm)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average distance from Environment data and GraphEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERCENTAGE ERROR OF GRAPH EVALUATOR FROM ENVIRONMENT (./Configs/config3.json):\n",
      "   - [MEAN] 0.0208341907010427\n",
      "   - [STD] 0.016339860922586425\n",
      "   - [MAX] 0.10378701842985763\n",
      "   - [MIN] 1.9434061694763793e-05\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from Environment import Environment\n",
    "from Model.Evaluator.GraphEvaluator import GraphEvaluator\n",
    "from Model.Evaluator.Baseline import Baseline\n",
    "from Model.Evaluator.OneStepEvaluator import OneStepEvaluator\n",
    "from Learner.BruteForce import *\n",
    "from Model.Product import *\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# ==== PARAMETERS TO CHANGE ====\n",
    "config_path = \"./Configs/config3.json\"\n",
    "RANDOM_ARM = False\n",
    "n_experiments = 100\n",
    "# ==============================\n",
    "\n",
    "f = open(config_path)\n",
    "config = json.load(f)\n",
    "f.close()\n",
    "\n",
    "user_means = []\n",
    "conf_classes = config[\"classes\"]\n",
    "for uc in conf_classes:\n",
    "  user_means.append(uc[\"usersMean\"])\n",
    "class_weights = np.array(user_means) / np.array(user_means).sum()\n",
    "\n",
    "env = Environment(config_path=config_path)\n",
    "marginsPerPrice = config[\"margins\"]\n",
    "num_prods = len(config[\"margins\"])\n",
    "num_prices = len(config[\"margins\"][0])\n",
    "\n",
    "evaluatorEnvDifference = []\n",
    "bf = BruteForce(num_prices=num_prices, num_products=num_prods)\n",
    "for i in tqdm(range(0, num_prices**num_prods)):\n",
    "  arm = bf.pull_arm() \n",
    "  margins = [marginsPerPrice[i][arm[i]] for i in range(0,len(arm))]\n",
    "  # print(margins)\n",
    "  obtained_margins = []\n",
    "\n",
    "  conf_classes = config[\"classes\"]\n",
    "  evaluators_rews = []\n",
    "  for uc in conf_classes:\n",
    "      armConvRates = [uc[\"conversionRates\"][i][arm[i]] for i in range(0,len(arm))]\n",
    "      productList = [Product(int(key), uc[\"secondary\"][key]) for key in uc[\"secondary\"]]\n",
    "      eval = GraphEvaluator(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                  alphas=uc[\"alphas\"], margins=margins, units_mean=uc[\"actualUnitsMean\"], convert_units=False, verbose=False)\n",
    "      evaluators_rews.append(eval.computeMargin())\n",
    "      baseline = Baseline(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                  alphas=uc[\"alphas\"], margins=margins, units_mean=uc[\"actualUnitsMean\"], convert_units=False, verbose=False)\n",
    "      oneStep = OneStepEvaluator(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                  alphas=uc[\"alphas\"], margins=margins, units_mean=uc[\"actualUnitsMean\"], verbose=False)\n",
    "\n",
    "  env.setPriceLevels(arm)\n",
    "  for i in range(0,n_experiments):\n",
    "    inters = env.round()\n",
    "    total = 0\n",
    "    for inter in inters:\n",
    "      total += inter.linearizeMargin(marginsPerPrice)\n",
    "      obtained_margins.append(inter.linearizeMargin(marginsPerPrice))\n",
    "    total = total / len(inters)\n",
    "  \n",
    "  environmentMean = np.array(obtained_margins).mean()\n",
    "  evaluatorMeanByClass = np.multiply(evaluators_rews, class_weights).sum()\n",
    "  # Percentage error of graph eval from environment\n",
    "  evaluatorEnvDifference.append(abs(environmentMean - evaluatorMeanByClass) / environmentMean)\n",
    "\n",
    "clear_output(wait=True)\n",
    "evaluatorEnvDifference = np.array(evaluatorEnvDifference)\n",
    "print(\"PERCENTAGE ERROR OF GRAPH EVALUATOR FROM ENVIRONMENT ({}):\".format(config_path))\n",
    "print(\"   - [MEAN] {}\".format(evaluatorEnvDifference.mean()))\n",
    "print(\"   - [STD] {}\".format(evaluatorEnvDifference.std()))\n",
    "print(\"   - [MAX] {}\".format(evaluatorEnvDifference.max()))\n",
    "print(\"   - [MIN] {}\".format(evaluatorEnvDifference.min()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visiting probability computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Evaluator vs Environment visiting probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIFFERENCE FROM ENVIRONMENT AND GE VISITING PROBABILITY, ARM [3 0 3 1 1] (./Configs/config3.json):\n",
      "   - [ENV] [0.30884901 0.36340768 0.32757561 0.2032534  0.225334  ]\n",
      "      - [STARTING 0] [1.         0.06621221 0.07291725 0.00502878 0.0101693 ]\n",
      "      - [STARTING 1] [0.00727802 1.         0.29067294 0.03459859 0.1231665 ]\n",
      "      - [STARTING 2] [0.01129944 0.02522795 1.         0.04609274 0.03753426]\n",
      "      - [STARTING 3] [0.21655659 0.15481921 0.06039404 1.         0.22428076]\n",
      "      - [STARTING 4] [0.03905066 0.64893677 0.18880099 0.1827414  1.        ]\n",
      "\n",
      "   - [G/E CLASS 0] [0.50951586 0.44942762 0.18946036 0.05136863 0.08975355]\n",
      "      - [STARTING 0] [1.         0.05103401 0.061328   0.00370889 0.00782575]\n",
      "      - [STARTING 1] [0.0060145  1.         0.28012485 0.03129359 0.12093545]\n",
      "      - [STARTING 2] [0.00857623 0.02301244 1.         0.04451584 0.03581747]\n",
      "      - [STARTING 3] [0.192      0.13574053 0.04683409 1.         0.20112673]\n",
      "      - [STARTING 4] [0.03356705 0.63059674 0.17804652 0.17387059 1.        ]\n",
      "   - [G/E CLASS 1] [0.11139883 0.28161958 0.48088646 0.31959554 0.32104673]\n",
      "      - [STARTING 0] [1.         0.0511817  0.061328   0.00388459 0.00782575]\n",
      "      - [STARTING 1] [0.00656637 1.         0.28014269 0.03416005 0.12093545]\n",
      "      - [STARTING 2] [0.00870426 0.0262304  1.         0.04516096 0.03581747]\n",
      "      - [STARTING 3] [0.192      0.15375726 0.05182764 1.         0.20112673]\n",
      "      - [STARTING 4] [0.03835521 0.7205161  0.20342407 0.19851571 1.        ]\n",
      "   - [G/E CLASS 2] [0.28679395 0.39771896 0.36149018 0.26186545 0.32516808]\n",
      "      - [STARTING 0] [1.         0.15554401 0.185088   0.01957619 0.03509936]\n",
      "      - [STARTING 1] [0.01564897 1.         0.32060643 0.04649886 0.15129935]\n",
      "      - [STARTING 2] [0.02951667 0.04919943 1.         0.08741888 0.08290555]\n",
      "      - [STARTING 3] [0.336      0.24051286 0.1212854  1.         0.35653614]\n",
      "      - [STARTING 4] [0.05280413 0.5433385  0.18047108 0.15583334 1.        ]\n",
      "\n",
      "   - [G/E TOTAL] [0.30707686 0.37012294 0.33893295 0.196394   0.22250985]\n",
      "\n",
      "PERFORMANCE INDEX => [0.00177215 0.00671526 0.01135734 0.0068594  0.00282416] => 0.005905662224066616\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from Environment import Environment\n",
    "from Model.Evaluator.GraphEvaluator import GraphEvaluator\n",
    "from Model.Evaluator.Baseline import Baseline\n",
    "from Model.Evaluator.OneStepEvaluator import OneStepEvaluator\n",
    "from Learner.BruteForce import *\n",
    "from Model.Product import *\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# ==== PARAMETERS TO CHANGE ====\n",
    "config_path = \"./Configs/config3.json\"\n",
    "RANDOM_ARM = True\n",
    "arm = [0, 0, 0, 0, 0]\n",
    "n_experiments = 250\n",
    "# ==============================\n",
    "\n",
    "f = open(config_path)\n",
    "config = json.load(f)\n",
    "f.close()\n",
    "\n",
    "env = Environment(config_path=config_path)\n",
    "marginsPerPrice = config[\"margins\"]\n",
    "num_prods = len(config[\"margins\"])\n",
    "num_prices = len(config[\"margins\"][0])\n",
    "\n",
    "if RANDOM_ARM:\n",
    "    arm = np.floor(np.random.rand(len(marginsPerPrice)) * len(marginsPerPrice[0]))\n",
    "    arm = np.array(arm.tolist(), dtype=int)\n",
    "env.setPriceLevels(arm)\n",
    "\n",
    "cumulative_visits = np.zeros(num_prods)\n",
    "cumulative_interactions = 0\n",
    "for i in tqdm(range(0,n_experiments)):\n",
    "    interactions = env.round()\n",
    "    cumulative_interactions += len(interactions)\n",
    "    for inter in interactions:\n",
    "        cumulative_visits = cumulative_visits + inter.linearizeVisits()\n",
    "clear_output(wait=True)\n",
    "\n",
    "environment_probs = cumulative_visits / cumulative_interactions\n",
    "print(\"DIFFERENCE FROM ENVIRONMENT AND GE VISITING PROBABILITY, ARM {} ({}):\".format(arm, config_path))\n",
    "print(\"   - [ENV] {}\".format(environment_probs))\n",
    "\n",
    "\n",
    "for j in range(0,num_prods):\n",
    "    for k in range(0,len(config[\"classes\"])):\n",
    "        env.classes[k].alphas = np.full(num_prods, 0.000001).tolist()\n",
    "        env.classes[k].alphas[j] = 1.00004\n",
    "    cumulative_visits = np.zeros(num_prods)\n",
    "    cumulative_interactions = 0\n",
    "    for i in range(0,n_experiments):\n",
    "        interactions = env.round()\n",
    "        cumulative_interactions += len(interactions)\n",
    "        for inter in interactions:\n",
    "            cumulative_visits = cumulative_visits + inter.linearizeVisits()\n",
    "    print(\"      - [STARTING {}] {}\".format(j, cumulative_visits / cumulative_interactions))\n",
    "print(\"\")\n",
    "conf_classes = config[\"classes\"]\n",
    "i = 0\n",
    "weighted_classes = np.zeros((num_prods))\n",
    "tot_users_daily = 0\n",
    "for uc in conf_classes:\n",
    "    armConvRates = [uc[\"conversionRates\"][i][arm[i]] for i in range(0,len(arm))]\n",
    "    productList = [Product(int(key), uc[\"secondary\"][key]) for key in uc[\"secondary\"]]\n",
    "    eval = GraphEvaluator(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                alphas=uc[\"alphas\"], margins=marginsPerPrice, units_mean=uc[\"actualUnitsMean\"], convert_units=False, verbose=False)\n",
    "    visit_prob = eval.getVisitingProbability()\n",
    "    weighted_classes = weighted_classes + visit_prob * uc[\"usersMean\"]\n",
    "    tot_users_daily += uc[\"usersMean\"]\n",
    "    print(\"   - [G/E CLASS {}] {}\".format(i, visit_prob))\n",
    "    for k in range(0,num_prods):\n",
    "        print(\"      - [STARTING {}] {}\".format(k, eval.computeSingleProduct(k)))\n",
    "    i += 1\n",
    "\n",
    "print(\"\")\n",
    "ge_weighted_probs = weighted_classes / tot_users_daily\n",
    "print(\"   - [G/E TOTAL] {}\\n\".format(ge_weighted_probs))\n",
    "\n",
    "print(\"PERFORMANCE INDEX => {} => {}\".format(np.abs(ge_weighted_probs - environment_probs), np.abs(ge_weighted_probs - environment_probs).mean()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph vs Environment visiting probability total performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN ABSOLUTE ERROR FROM GRAPH EVALUATOR TO ENVIRONMENT (./Configs/config3.json):\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\School\\2021.22\\II Semestre\\Online Learning Applications\\Project\\team4_projectOLA\\Utilities.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/2021.22/II%20Semestre/Online%20Learning%20Applications/Project/team4_projectOLA/Utilities.ipynb#ch0000013?line=59'>60</a>\u001b[0m clear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/2021.22/II%20Semestre/Online%20Learning%20Applications/Project/team4_projectOLA/Utilities.ipynb#ch0000013?line=61'>62</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMEAN ABSOLUTE ERROR FROM GRAPH EVALUATOR TO ENVIRONMENT (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m):\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(config_path))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/School/2021.22/II%20Semestre/Online%20Learning%20Applications/Project/team4_projectOLA/Utilities.ipynb#ch0000013?line=62'>63</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m   - [MEAN] \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(distances_index\u001b[39m.\u001b[39;49mmean()))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/2021.22/II%20Semestre/Online%20Learning%20Applications/Project/team4_projectOLA/Utilities.ipynb#ch0000013?line=63'>64</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m   - [STD] \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(distances_index\u001b[39m.\u001b[39mstd()))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/2021.22/II%20Semestre/Online%20Learning%20Applications/Project/team4_projectOLA/Utilities.ipynb#ch0000013?line=64'>65</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m   - [MAX] \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(distances_index\u001b[39m.\u001b[39mmax()))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'mean'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from Environment import Environment\n",
    "from Model.Evaluator.GraphEvaluator import GraphEvaluator\n",
    "from Model.Evaluator.Baseline import Baseline\n",
    "from Model.Evaluator.OneStepEvaluator import OneStepEvaluator\n",
    "from Learner.BruteForce import *\n",
    "from Model.Product import *\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# ==== PARAMETERS TO CHANGE ====\n",
    "config_path = \"./Configs/config3.json\"\n",
    "n_experiments = 100\n",
    "# ==============================\n",
    "\n",
    "f = open(config_path)\n",
    "config = json.load(f)\n",
    "f.close()\n",
    "\n",
    "env = Environment(config_path=config_path)\n",
    "marginsPerPrice = config[\"margins\"]\n",
    "num_prods = len(config[\"margins\"])\n",
    "num_prices = len(config[\"margins\"][0])\n",
    "\n",
    "distances_index = []\n",
    "for i in tqdm(range(0, num_prices**num_prods)):\n",
    "    arm = bf.pull_arm() \n",
    "    env.setPriceLevels(arm)\n",
    "\n",
    "    cumulative_visits = np.zeros(num_prods)\n",
    "    cumulative_interactions = 0\n",
    "    for i in range(0,n_experiments):\n",
    "        interactions = env.round()\n",
    "        cumulative_interactions += len(interactions)\n",
    "        for inter in interactions:\n",
    "            cumulative_visits = cumulative_visits + inter.linearizeVisits()\n",
    "    \n",
    "\n",
    "    environment_probs = cumulative_visits / cumulative_interactions\n",
    "\n",
    "    conf_classes = config[\"classes\"]\n",
    "    i = 0\n",
    "    weighted_classes = np.zeros((num_prods))\n",
    "    tot_users_daily = 0\n",
    "    for uc in conf_classes:\n",
    "        armConvRates = [uc[\"conversionRates\"][i][arm[i]] for i in range(0,len(arm))]\n",
    "        productList = [Product(int(key), uc[\"secondary\"][key]) for key in uc[\"secondary\"]]\n",
    "        eval = GraphEvaluator(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                    alphas=uc[\"alphas\"], margins=marginsPerPrice, units_mean=uc[\"actualUnitsMean\"], convert_units=False, verbose=False)\n",
    "        visit_prob = eval.getVisitingProbability()\n",
    "        weighted_classes = weighted_classes + visit_prob * uc[\"usersMean\"]\n",
    "        tot_users_daily += uc[\"usersMean\"]\n",
    "        i += 1\n",
    "\n",
    "    ge_weighted_probs = weighted_classes / tot_users_daily\n",
    "\n",
    "    distances_index.append(np.abs(ge_weighted_probs - environment_probs).mean())\n",
    "\n",
    "clear_output(wait=True)\n",
    "distances_index = np.array(distances_index)\n",
    "\n",
    "print(\"MEAN ABSOLUTE ERROR OF VISITING PROBABILITY FROM GRAPH EVALUATOR TO ENVIRONMENT ({}):\".format(config_path))\n",
    "print(\"   - [MEAN] {}\".format(distances_index.mean()))\n",
    "print(\"   - [STD] {}\".format(distances_index.std()))\n",
    "print(\"   - [MAX] {}\".format(distances_index.max()))\n",
    "print(\"   - [MIN] {}\".format(distances_index.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN ABSOLUTE ERROR FROM GRAPH EVALUATOR TO ENVIRONMENT (./Configs/config3.json):\n",
      "   - [MEAN] 0.015544944923210742\n",
      "   - [STD] 0.002981508112788395\n",
      "   - [MAX] 0.026192905821785472\n",
      "   - [MIN] 0.007054892092087162\n"
     ]
    }
   ],
   "source": [
    "distances_index = np.array(distances_index)\n",
    "\n",
    "print(\"MEAN ABSOLUTE ERROR FROM GRAPH EVALUATOR TO ENVIRONMENT ({}):\".format(config_path))\n",
    "print(\"   - [MEAN] {}\".format(distances_index.mean()))\n",
    "print(\"   - [STD] {}\".format(distances_index.std()))\n",
    "print(\"   - [MAX] {}\".format(distances_index.max()))\n",
    "print(\"   - [MIN] {}\".format(distances_index.min()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration clairevoyancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming units shape in units mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE TRANSFORMATION:\n",
      "   - [DISTRO] [0.94, 1.45, 1.2, 2.0, 1.5]\n",
      "   - [SAMPLING] [1.5321, 1.9754, 1.7497, 2.504, 2.0233]\n",
      "   - [GAMMA SCIPY] [1.527, 1.9716, 1.7454, 2.4968, 2.0175]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import gamma\n",
    "\n",
    "units_mean = [0.94, 1.45, 1.2, 2.0, 1.5]\n",
    "actual_means = []\n",
    "for i in range(0,len(units_mean)):\n",
    "    empiric_mean = np.ceil(np.random.gamma(units_mean[i], 1, size=1000000)).mean()\n",
    "    actual_means.append(int(empiric_mean*10000) / 10000)\n",
    "print(\"SHAPE TRANSFORMATION:\")\n",
    "print(\"   - [DISTRO] {}\".format(units_mean))\n",
    "print(\"   - [SAMPLING] {}\".format(actual_means))\n",
    "\n",
    "actual_means = []\n",
    "for i in range(0,len(units_mean)):\n",
    "    # empiric_mean = np.ceil(np.random.gamma(units_mean[i], 1, size=1000000)).mean()\n",
    "    # New method using cumulative distribution, difference empiric and theoretic < 0.01\n",
    "    significant = True\n",
    "    theoretic_mean = 0\n",
    "    num = 1\n",
    "    while significant:\n",
    "        t = (gamma.cdf(num, a=units_mean[i]) - gamma.cdf(num - 1, a=units_mean[i])) * num\n",
    "        theoretic_mean += t\n",
    "        num += 1\n",
    "        if t < 0.01:\n",
    "            significant = False\n",
    "    #print(num)\n",
    "    actual_means.append(int(theoretic_mean*10000) / 10000)\n",
    "#print(actual_means)\n",
    "units_mean = np.array(actual_means)\n",
    "print(\"   - [GAMMA SCIPY] {}\".format(actual_means))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the best arm for each class by brute force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRUTE FORCE OF CONFIG ./Configs/config2.json CLASSES:\n",
      "   - [CLASS 0] Optimal arm is [1, 1, 1, 1, 1] with margin 8.115400000000001\n",
      "   - [CLASS 1] Optimal arm is [1, 1, 1, 1, 1] with margin 10.5175\n",
      "   - [CLASS 2] Optimal arm is [2, 2, 1, 2, 1] with margin 13.132000000000001\n",
      "\n",
      "The optimal weighted mean expected margin given the mean daily users [30 30 10] is 9.86152857142857\n",
      "\n",
      "Which arm among the best ones gives the better results in non contextual optmization?\n",
      "   - [ARM [1, 1, 1, 1, 1]] Class-weighted expected margin is 9.86152857142857, but baseline is greater than weighted\n",
      "   - [ARM [1, 1, 1, 1, 1]] Class-weighted expected margin is 9.86152857142857, but baseline is greater than weighted\n",
      "   - [ARM [2, 2, 1, 2, 1]] Class-weighted expected margin is 9.21652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:02<00:00, 476.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRUTE FORCE BY WEIGHTING CLASSES REWARDS:\n",
      "   - [THEORY] Optimal arm is [1, 1, 1, 1, 1] with margin 9.86152857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from Environment import Environment\n",
    "import numpy as np\n",
    "from Learner.BruteForce import *\n",
    "from Model.UserClass import *\n",
    "from Model.Product import *\n",
    "from Model.GraphProbabilities import *\n",
    "from Model.Evaluator.GraphEvaluator import GraphEvaluator\n",
    "from Model.Evaluator.Baseline import Baseline\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "\n",
    "# ==== PARAMETERS TO CHANGE ====\n",
    "CONFIG_PATH = './Configs/config2.json'\n",
    "# ==============================\n",
    "\n",
    "\n",
    "f = open(CONFIG_PATH)\n",
    "config = json.load(f)\n",
    "f.close()\n",
    "\n",
    "opt_arms = []\n",
    "opt_margins = []\n",
    "daily_users = []\n",
    "print(\"Starting the analysis ...\\n\")\n",
    "for k in range(0, len(config[\"classes\"])):\n",
    "    uc = config[\"classes\"][k]\n",
    "\n",
    "    productList = [Product(int(key), uc[\"secondary\"][key]) for key in uc[\"secondary\"]]\n",
    "\n",
    "    conversionRateLevels = uc[\"conversionRates\"]\n",
    "    marginsPerPrice = config[\"margins\"]\n",
    "    click_prob = np.array(uc[\"clickProbability\"])\n",
    "    lambda_p = uc[\"lambda\"]\n",
    "    alphas = uc[\"alphas\"]\n",
    "    units_mean = uc[\"actualUnitsMean\"]\n",
    "    # Early transform for efficiency reason\n",
    "    # actual_means = []\n",
    "    # for i in range(0,len(units_mean)):\n",
    "    #    empiric_mean = np.ceil(np.random.gamma(units_mean[i], 1, size=1000000)).mean()\n",
    "    #     actual_means.append(int(empiric_mean*100) / 100)\n",
    "    # units_mean = actual_means\n",
    "\n",
    "    daily_users.append(uc[\"usersMean\"])\n",
    "    num_prices = len(conversionRateLevels[0])\n",
    "    num_prods = len(alphas)\n",
    "\n",
    "    print(\"Brute forcing class {}\".format(k))\n",
    "    bf = BruteForce(num_prices=num_prices, num_products=num_prods)\n",
    "    for i in tqdm(range(0, num_prices**num_prods)):\n",
    "        pulledArm = bf.pull_arm()\n",
    "        margins = []\n",
    "        convRates = []\n",
    "        for k in range(0,len(pulledArm)):\n",
    "            margins.append(marginsPerPrice[k][pulledArm[k]])\n",
    "            convRates.append(conversionRateLevels[k][pulledArm[k]])\n",
    "\n",
    "        price_configuration_margin = 0\n",
    "        eval = GraphEvaluator(products_list=productList, click_prob_matrix=click_prob, lambda_prob=lambda_p, conversion_rates=convRates,\n",
    "                        alphas=alphas, margins=margins, units_mean=units_mean, convert_units=False, verbose=False)\n",
    "        eval2 = Baseline(products_list=productList, click_prob_matrix=click_prob, lambda_prob=lambda_p, conversion_rates=convRates,\n",
    "                        alphas=alphas, margins=margins, units_mean=units_mean, convert_units=False, verbose=False)\n",
    "\n",
    "        overall_margin = eval.computeMargin()\n",
    "        baseline = eval2.computeMargin()\n",
    "        # print(\"Configuration {}; ConvRates {}; Margins {}; Overall Margin {}; Baseline {}\".format(pulledArm,convRates,margins,int(overall_margin*100)/100,int(baseline*100)/100))\n",
    "        # if overall_margin < baseline:\n",
    "            # print(\"VAFFANCULOOOOO {} - {} = {}\".format(overall_margin,baseline,overall_margin-baseline))\n",
    "        bf.update(overall_margin)\n",
    "\n",
    "    opt_arms.append(bf.get_optima())\n",
    "    opt_margins.append(bf.get_optima_margin())\n",
    "clear_output(wait=True)\n",
    "print(\"BRUTE FORCE OF CONFIG {} CLASSES:\".format(CONFIG_PATH))\n",
    "for i in range(0,len(opt_arms)):\n",
    "    print(\"   - [CLASS {}] Optimal arm is {} with margin {}\".format(i,opt_arms[i], opt_margins[i]))\n",
    "\n",
    "daily_users = np.array(daily_users)\n",
    "classes_weights = daily_users / daily_users.sum()\n",
    "opt_margins = np.array(opt_margins)\n",
    "print(\"\\nThe optimal weighted mean expected margin given the mean daily users {} is {}\".format(daily_users, np.multiply(classes_weights, opt_margins).sum()))\n",
    "\n",
    "# Best single arm possible\n",
    "print(\"\\nWhich arm among the best ones gives the better results in non contextual optmization?\")\n",
    "equal_arm_rew = []\n",
    "for i in range(0,len(opt_arms)):\n",
    "    arm = opt_arms[i]\n",
    "    class_rewards = []\n",
    "    for k in range(0, len(config[\"classes\"])):\n",
    "        uc = config[\"classes\"][k]\n",
    "        productList = [Product(int(key), uc[\"secondary\"][key]) for key in uc[\"secondary\"]]\n",
    "        conversionRateLevels = uc[\"conversionRates\"]\n",
    "        marginsPerPrice = config[\"margins\"]\n",
    "        click_prob = np.array(uc[\"clickProbability\"])\n",
    "        lambda_p = uc[\"lambda\"]\n",
    "        alphas = uc[\"alphas\"]\n",
    "        units_mean = uc[\"unitsShape\"]\n",
    "        num_prices = len(conversionRateLevels[0])\n",
    "        num_prods = len(alphas)\n",
    "\n",
    "        pulledArm = arm\n",
    "        margins = []\n",
    "        convRates = []\n",
    "        for k in range(0,len(pulledArm)):\n",
    "            margins.append(marginsPerPrice[k][pulledArm[k]])\n",
    "            convRates.append(conversionRateLevels[k][pulledArm[k]])\n",
    "\n",
    "        eval = GraphEvaluator(products_list=productList, click_prob_matrix=click_prob, lambda_prob=lambda_p, conversion_rates=convRates,\n",
    "                        alphas=alphas, margins=margins, units_mean=units_mean, verbose=False)\n",
    "        eval2 = Baseline(products_list=productList, click_prob_matrix=click_prob, lambda_prob=lambda_p, conversion_rates=convRates,\n",
    "                        alphas=alphas, margins=margins, units_mean=units_mean, verbose=False)\n",
    "                    \n",
    "        class_rewards.append(eval.computeMargin())\n",
    "    \n",
    "    weighted_reward = np.multiply(classes_weights, np.array(class_rewards)).sum()\n",
    "    equal_arm_rew.append(weighted_reward)\n",
    "    if class_rewards[i] < eval2.computeMargin():\n",
    "        print(\"   - [ARM {}] Class-weighted expected margin is {}, but baseline is greater than weighted\".format(arm, weighted_reward))\n",
    "    else:\n",
    "        print(\"   - [ARM {}] Class-weighted expected margin is {}\".format(arm, weighted_reward))\n",
    "\n",
    "\n",
    "user_means = []\n",
    "conf_classes = config[\"classes\"]\n",
    "for uc in conf_classes:\n",
    "  user_means.append(uc[\"usersMean\"])\n",
    "class_weights = np.array(user_means) / np.array(user_means).sum()\n",
    "\n",
    "bf = BruteForce(num_prices=num_prices, num_products=num_prods)\n",
    "for i in tqdm(range(0, num_prices**num_prods)):\n",
    "    arm = bf.pull_arm() \n",
    "    margins = [marginsPerPrice[i][arm[i]] for i in range(0,len(arm))]\n",
    "\n",
    "    obtained_margins = []\n",
    "\n",
    "    conf_classes = config[\"classes\"]\n",
    "    evaluators_rews = []\n",
    "    for uc in conf_classes:\n",
    "        armConvRates = [uc[\"conversionRates\"][i][arm[i]] for i in range(0,len(arm))]\n",
    "        productList = [Product(int(key), uc[\"secondary\"][key]) for key in uc[\"secondary\"]]\n",
    "        eval = GraphEvaluator(products_list=productList, click_prob_matrix=uc[\"clickProbability\"], lambda_prob=uc[\"lambda\"], conversion_rates=armConvRates,\n",
    "                    alphas=uc[\"alphas\"], margins=margins, units_mean=uc[\"actualUnitsMean\"], convert_units=False, verbose=False)\n",
    "        evaluators_rews.append(eval.computeMargin())    \n",
    "\n",
    "    evaluatorMeanByClass = np.multiply(evaluators_rews, class_weights).sum()\n",
    "    bf.update(evaluatorMeanByClass)\n",
    "\n",
    "print(\"BRUTE FORCE BY WEIGHTING CLASSES REWARDS:\".format(CONFIG_PATH))\n",
    "print(\"   - [THEORY] Optimal arm is {} with margin {}\".format(bf.get_optima(), bf.get_optima_margin()))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "14160fb0de3f36180f5e1dd791af52bebcb3f3583a6e540ccb943ed2b61e8d42"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
